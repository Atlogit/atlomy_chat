name: Production Deployment to EC2

on:
  workflow_run:
    workflows: ["Docker Build and Registry Push"]
    types:
      - completed
    branches:
      - production
  workflow_dispatch:
    inputs:
      force_deploy:
        description: 'Force deployment without Docker Build workflow'
        required: false
        type: boolean
        default: false

# Comprehensive permissions for GitHub Actions workflow
permissions:
  contents: read
  packages: read
  id-token: write

env:
  BACKEND_IMAGE_NAME: ${{ github.repository }}-backend
  FRONTEND_IMAGE_NAME: ${{ github.repository }}-frontend

jobs:
  # Database Restoration Job
  database-restoration:
    uses: ./.github/workflows/database-restoration.yml
    secrets: inherit
    with:
      deployment_mode: production

  # Database Initialization and Setup
  database-initialization:
    needs: database-restoration
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'

      - name: Configure AWS Credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: ${{ secrets.AWS_OIDC_ROLE_ARN }}
          aws-region: us-east-1

      - name: Retrieve Database Secrets
        id: get-database-secrets
        run: |
          secrets=$(aws secretsmanager get-secret-value --secret-id amta-production-secrets --query SecretString --output text)
          
          database_url=$(echo $secrets | jq -r '.DATABASE_URL')
          postgres_host=$(echo $secrets | jq -r '.POSTGRES_HOST')
          postgres_port=$(echo $secrets | jq -r '.POSTGRES_PORT')
          postgres_db=$(echo $secrets | jq -r '.POSTGRES_DB')
          postgres_user=$(echo $secrets | jq -r '.POSTGRES_USER')
          
          echo "::add-mask::$database_url"
          echo "DATABASE_URL=$database_url" >> $GITHUB_OUTPUT
          echo "POSTGRES_HOST=$postgres_host" >> $GITHUB_OUTPUT
          echo "POSTGRES_PORT=$postgres_port" >> $GITHUB_OUTPUT
          echo "POSTGRES_DB=$postgres_db" >> $GITHUB_OUTPUT
          echo "POSTGRES_USER=$postgres_user" >> $GITHUB_OUTPUT

      - name: Install Dependencies
        run: |
          python -m pip install --upgrade pip
          pip install sqlalchemy psycopg2-binary alembic

      - name: Database Initialization Check
        env:
          DATABASE_URL: ${{ steps.get-database-secrets.outputs.DATABASE_URL }}
          POSTGRES_HOST: ${{ steps.get-database-secrets.outputs.POSTGRES_HOST }}
          POSTGRES_PORT: ${{ steps.get-database-secrets.outputs.POSTGRES_PORT }}
          POSTGRES_DB: ${{ steps.get-database-secrets.outputs.POSTGRES_DB }}
          POSTGRES_USER: ${{ steps.get-database-secrets.outputs.POSTGRES_USER }}
        run: |
          python3 - << EOF
          import os
          import sqlalchemy
          from sqlalchemy import create_engine, text
          from sqlalchemy.exc import SQLAlchemyError, ProgrammingError

          def check_database_exists(engine, database_name):
              try:
                  with engine.connect() as connection:
                      result = connection.execute(
                          text(f"SELECT 1 FROM pg_catalog.pg_database WHERE datname = '{database_name}'")
                      )
                      return result.scalar() is not None
              except Exception as e:
                  print(f"Error checking database: {e}")
                  return False

          def create_database(engine, database_name, user):
              try:
                  with engine.connect() as connection:
                      connection.execute(text("commit"))
                      connection.execute(text(f"CREATE DATABASE {database_name}"))
                      connection.execute(text(f"GRANT ALL PRIVILEGES ON DATABASE {database_name} TO {user}"))
                  print(f"Database {database_name} created successfully")
                  return True
              except Exception as e:
                  print(f"Error creating database: {e}")
                  return False

          # Connection URL without specific database
          base_url = os.environ['DATABASE_URL'].replace(f"/{os.environ['POSTGRES_DB']}", "/postgres")
          
          engine = create_engine(base_url)
          
          if not check_database_exists(engine, os.environ['POSTGRES_DB']):
              print("Database does not exist. Creating...")
              if create_database(engine, os.environ['POSTGRES_DB'], os.environ['POSTGRES_USER']):
                  print("✅ Database initialization successful")
              else:
                  print("❌ Database initialization failed")
                  exit(1)
          else:
              print("✅ Database already exists")
          EOF

      - name: Run Database Migrations
        run: |
          alembic upgrade head

  # Deployment Readiness Verification
  deployment-readiness:
    needs: database-initialization
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          ref: production
          fetch-depth: 0

      - name: Set up deployment environment
        run: |
          # Ensure all verification scripts are executable
          chmod +x deployment_readiness.sh verify_deployment.sh

      - name: Run Deployment Readiness Checks
        run: |
          # Run deployment readiness script
          ./deployment_readiness.sh production
        env:
          DEPLOYMENT_MODE: production

  # Primary deployment job
  deploy-to-ec2:
    needs: deployment-readiness
    # Conditional execution based on workflow trigger or manual dispatch
    if: |
      (github.event_name == 'workflow_dispatch') ||
      (github.event.workflow_run.conclusion == 'success' && 
       github.event.workflow_run.name == 'Docker Build and Registry Push' &&
       (github.event.workflow_run.head_branch == 'production' || 
        contains(github.event.workflow_run.head_branch, 'production')))
    runs-on: ubuntu-latest
    permissions:
      contents: read
      packages: read
      id-token: write

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          ref: production
          fetch-depth: 0

      # Deployment Logging Preparation
      - name: Prepare Deployment Logs
        run: |
          mkdir -p deployment_logs
          chmod 777 deployment_logs
          echo "Workflow initiated at $(date)" > deployment_logs/workflow_start.log
          echo "Repository: ${{ github.repository }}" >> deployment_logs/workflow_start.log
          echo "Workflow Run ID: ${{ github.run_id }}" >> deployment_logs/workflow_start.log
          ls -la deployment_logs

      - name: Login to GitHub Container Registry
        uses: docker/login-action@v3
        with:
          registry: ghcr.io
          username: ${{ github.actor }}
          password: ${{ secrets.GITHUB_TOKEN }}

      - name: Pull Backend Docker Image
        run: |
          BACKEND_REPO_LOWER=$(echo "${{ env.BACKEND_IMAGE_NAME }}" | tr '[:upper:]' '[:lower:]')
          docker pull ghcr.io/$BACKEND_REPO_LOWER:production || true

      - name: Pull Frontend Docker Image
        run: |
          FRONTEND_REPO_LOWER=$(echo "${{ env.FRONTEND_IMAGE_NAME }}" | tr '[:upper:]' '[:lower:]')
          docker pull ghcr.io/$FRONTEND_REPO_LOWER:production || true

      - name: Configure AWS Credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: ${{ secrets.AWS_OIDC_ROLE_ARN }}
          aws-region: us-east-1

      - name: Retrieve Production Secrets
        id: get-secrets
        run: |
          secrets=$(aws secretsmanager get-secret-value --secret-id amta-production-secrets --query SecretString --output text)
          
          redis_url=$(echo $secrets | jq -r '.REDIS_URL')
          bedrock_model_id=$(echo $secrets | jq -r '.BEDROCK_MODEL_ID')
          
          echo "::add-mask::$redis_url"
          echo "::add-mask::$bedrock_model_id"
          
          echo "REDIS_URL=$redis_url" >> $GITHUB_OUTPUT
          echo "BEDROCK_MODEL_ID=$bedrock_model_id" >> $GITHUB_OUTPUT

      - name: Prepare Deployment Configuration
        env:
          REDIS_URL: ${{ steps.get-secrets.outputs.REDIS_URL }}
          BEDROCK_MODEL_ID: ${{ steps.get-secrets.outputs.BEDROCK_MODEL_ID }}
        run: |
          echo "DEPLOYMENT_MODE=production" > .env
          echo "REDIS_URL=$REDIS_URL" >> .env
          echo "BEDROCK_MODEL_ID=$BEDROCK_MODEL_ID" >> .env
          echo "AWS_REGION=us-east-1" >> .env
          chmod 600 .env

      - name: Deploy to EC2
        env:
          EC2_SSH_KEY: ${{ secrets.EC2_SSH_PRIVATE_KEY }}
          EC2_HOST: ${{ secrets.EC2_HOST }}
          EC2_USER: ${{ secrets.EC2_USER }}
        run: |
          mkdir -p ~/.ssh
          echo "$EC2_SSH_KEY" > ~/.ssh/ec2_key
          chmod 600 ~/.ssh/ec2_key

          SSH_OPTS="-o BatchMode=yes -o StrictHostKeyChecking=no"

          # Setup EC2 environment
          ssh $SSH_OPTS -i ~/.ssh/ec2_key $EC2_USER@$EC2_HOST << SETUP_EOF
            HOME_DIR=\$(eval echo ~$EC2_USER)
            mkdir -p \$HOME_DIR/atlomy_chat/logs
            chmod 750 \$HOME_DIR/atlomy_chat/logs
            echo "Deployment initiated at \$(date)" > \$HOME_DIR/atlomy_chat/logs/deployment.log
          SETUP_EOF

          # Copy deployment files
          scp $SSH_OPTS -i ~/.ssh/ec2_key \
              docker-compose.yml .env \
              $EC2_USER@$EC2_HOST:~/atlomy_chat/

          # Deploy services
          ssh $SSH_OPTS -i ~/.ssh/ec2_key $EC2_USER@$EC2_HOST << DEPLOY_EOF
            HOME_DIR=\$(eval echo ~$EC2_USER)
            cd \$HOME_DIR/atlomy_chat
            
            # Pull latest images
            docker pull ghcr.io/$(echo "${{ env.BACKEND_IMAGE_NAME }}" | tr '[:upper:]' '[:lower:]'):production
            docker pull ghcr.io/$(echo "${{ env.FRONTEND_IMAGE_NAME }}" | tr '[:upper:]' '[:lower:]'):production
            
            # Stop and remove existing containers
            docker-compose down || true
            
            # Start new deployment
            docker-compose up -d
            
            # Log container status
            docker-compose ps
            docker-compose logs --tail=100
          DEPLOY_EOF

      - name: Verify Deployment
        run: |
          # Run comprehensive deployment verification
          ./verify_deployment.sh

      - name: Verify Deployment Health
        env:
          EC2_SSH_KEY: ${{ secrets.EC2_SSH_PRIVATE_KEY }}
          EC2_HOST: ${{ secrets.EC2_HOST }}
          EC2_USER: ${{ secrets.EC2_USER }}
        run: |
          SSH_OPTS="-o BatchMode=yes -o StrictHostKeyChecking=no"
          
          ssh $SSH_OPTS -i ~/.ssh/ec2_key $EC2_USER@$EC2_HOST << HEALTH_EOF
            HOME_DIR=\$(eval echo ~$EC2_USER)
            cd \$HOME_DIR/atlomy_chat
            
            max_attempts=3
            attempt=0
            
            while [ \$attempt -lt \$max_attempts ]; do
              echo "Health Check Attempt \$((attempt + 1))"
              
              backend_response=\$(curl -s -w "%{http_code}" http://localhost:8081/health)
              frontend_response=\$(curl -s -w "%{http_code}" http://localhost:3000)
              
              backend_status=\${backend_response: -3}
              frontend_status=\${frontend_response: -3}
              
              if [ "\$backend_status" = "200" ] && [ "\$frontend_status" = "200" ]; then
                echo "Successful Health Check: Both Backend and Frontend are Operational"
                exit 0
              fi
              
              echo "Health Check Failed. Backend Status: \$backend_status, Frontend Status: \$frontend_status"
              docker-compose logs --tail=100
              
              attempt=\$((attempt + 1))
              sleep 15
            done
            
            echo "Critical: Health Checks Failed After \$max_attempts Attempts"
            exit 1
          HEALTH_EOF

      - name: Preserve Deployment Logs
        if: always()
        uses: actions/upload-artifact@v3
        with:
          name: deployment-logs
          path: |
            deployment_logs/
            ${{ github.workspace }}/deployment_logs/
          retention-days: 7

      - name: Generate Fallback Logs
        if: failure()
        run: |
          mkdir -p deployment_logs
          echo "Workflow Failed" > deployment_logs/workflow_failure.log
          echo "Workflow Run ID: ${{ github.run_id }}" >> deployment_logs/workflow_failure.log
          echo "Repository: ${{ github.repository }}" >> deployment_logs/workflow_failure.log
          env >> deployment_logs/environment_vars.log
