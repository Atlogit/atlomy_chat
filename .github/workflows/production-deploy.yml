name: Production Deployment Workflow

on:
  workflow_dispatch:
    inputs:
      deployment_mode:
        description: 'Deployment mode (development/production)'
        required: false
        default: 'production'
        type: choice
        options:
          - production
          - development
      postgres_data_dir:  
        description: 'PostgreSQL Data Directory'
        required: false
        default: '/home/ec2-user/amta/postgresql/data'
      force_deploy:
        description: 'Force deployment without Docker Build workflow'
        required: false
        type: boolean
        default: false
      frontend_tag:
        description: 'Frontend image tag (optional - will use latest if not specified)'
        required: false
        type: string
      backend_tag:
        description: 'Backend image tag (optional - will use latest if not specified)'
        required: false
        type: string
      backup_type:
        description: 'Backup Type for Database Restoration'
        required: true
        type: choice
        options:
          - tar
          - sql
        default: sql
  workflow_run:
    workflows: ["Docker Build and Registry Push"]
    types:
      - completed
    branches:
      - production

# Comprehensive permissions for GitHub Actions workflow
permissions:
  contents: read
  actions: read
  packages: read
  id-token: write

env:
  BACKEND_IMAGE_NAME: ${{ github.repository }}-backend
  FRONTEND_IMAGE_NAME: ${{ github.repository }}-frontend

jobs:
  validate-workflow-trigger:
    runs-on: ubuntu-latest
    steps:
      - name: Validate Workflow Trigger
        run: |
          echo "🔍 Workflow Trigger Analysis:"
          echo "Event Name: ${{ github.event_name }}"
          echo "Workflow Run Conclusion: ${{ github.event.workflow_run.conclusion }}"
          echo "Workflow Run Name: ${{ github.event.workflow_run.name }}"
          echo "Workflow Run Branch: ${{ github.event.workflow_run.head_branch }}"

  #database-restoration:
  #  needs: validate-workflow-trigger
  #  uses: ./.github/workflows/database-restoration.yml
  #  secrets: inherit
  #  with:
  #    deployment_mode: production
  #    backup_type: ${{ inputs.backup_type || 'tar' }}
  #    postgres_data_dir: ${{ inputs.postgres_data_dir }}
 # 
 # database-validation:
 #   needs: database-restoration
 #   uses: ./.github/workflows/database-validation.yml
 #   secrets: inherit
 #   with:
 #     deployment_mode: production

  deploy-to-ec2:
  #  needs: 
  #    - database-restoration
    if: github.event_name == 'workflow_dispatch' || (github.event_name == 'workflow_run' && github.event.workflow_run.head_branch == 'production' && github.event.workflow_run.conclusion == 'success' )
    runs-on: ubuntu-latest
    environment: ${{ inputs.deployment_mode }}
    steps:
      - name: Debug Workflow
        run: |
          echo "Event type: ${{ github.event_name }}"
          echo "Workflow: ${{ github.event.workflow_run.name }}"
          echo "Branch: ${{ github.event.workflow_run.head_branch }}"
          echo "Conclusion: ${{ github.event.workflow_run.conclusion }}"
          
      - name: Checkout Repository
        uses: actions/checkout@v4
        with:
          ref: production
          fetch-depth: 0
            
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Install System Dependencies
        run: |
          sudo apt-get update
          sudo apt-get install -y jq

      - name: Install Python Dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          pip install boto3 botocore awscli
          pip install typing-extensions pydantic pydantic-settings

      - name: Debug Workflow Run Info
        if: github.event_name == 'workflow_run'
        run: |
          echo "Workflow Run ID: ${{ github.event.workflow_run.id }}"
          echo "Workflow Name: ${{ github.event.workflow_run.name }}"
          echo "Attempting to list artifacts..."
          gh run list-files ${{ github.event.workflow_run.id }}
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
  
      - name: Set deployment tags
        run: |
            if [ "${{ github.event_name }}" == "workflow_run" ]; then
              mkdir -p artifacts
              echo "Attempting to download artifacts..."
              # Use the GitHub REST API to get artifact information
              artifacts_url="${{ github.event.workflow_run.artifacts_url }}"
              echo "Artifacts URL: $artifacts_url"
              
              curl -L \
                -H "Accept: application/vnd.github+json" \
                -H "Authorization: Bearer ${{ secrets.GITHUB_TOKEN }}" \
                -H "X-GitHub-Api-Version: 2022-11-28" \
                $artifacts_url

              if [ -f "artifacts/build-tags.txt" ]; then
                source artifacts/build-tags.txt
                echo "FRONTEND_TAG=${FRONTEND_TAG}" >> $GITHUB_ENV
                echo "BACKEND_TAG=${BACKEND_TAG}" >> $GITHUB_ENV
              else
                echo "Warning: Could not find build tags, using default tags"
                echo "FRONTEND_TAG=latest" >> $GITHUB_ENV
                echo "BACKEND_TAG=latest" >> $GITHUB_ENV
              fi
            else
              # Manual deployment - use inputs or 'latest'
              FRONTEND_TAG="${{ inputs.frontend_tag || 'latest' }}"
              BACKEND_TAG="${{ inputs.backend_tag || 'latest' }}"
              echo "FRONTEND_TAG=${FRONTEND_TAG}" >> $GITHUB_ENV
              echo "BACKEND_TAG=${BACKEND_TAG}" >> $GITHUB_ENV
            fi

      - name: Debug Tags
        run: |
          echo "Frontend Tag: ${{ env.FRONTEND_TAG }}"
          echo "Backend Tag: ${{ env.BACKEND_TAG }}"

      - name: Prepare Deployment Logs
        run: |
          mkdir -p deployment_logs
          chmod 777 deployment_logs
          echo "Workflow initiated at $(date)" > deployment_logs/workflow_start.log
          echo "Repository: ${{ github.repository }}" >> deployment_logs/workflow_start.log
          echo "Workflow Run ID: ${{ github.run_id }}" >> deployment_logs/workflow_start.log
          ls -la deployment_logs

      - name: Configure AWS Credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: ${{ secrets.AWS_OIDC_ROLE_ARN }}
          aws-region: us-east-1


      - name: Retrieve Production Secrets
        id: get-secrets
        run: |
          secrets=$(aws secretsmanager get-secret-value --secret-id amta-production-secrets --query SecretString --output text)
          
          # Comprehensive secret extraction
          database_url=$(echo "$secrets" | jq -r '.DATABASE_URL')
          
          # Validate database URL
          if [ -z "$database_url" ]; then
            echo "❌ DATABASE_URL not found in secrets"
            exit 1
          fi
          
          # Extract database connection parameters using dynamic parsing
          postgres_host=$(echo "$database_url" | sed -E 's|postgresql\+asyncpg://[^:]+:[^@]+@([^:/]+).*|\1|')
          postgres_db=$(echo "$database_url" | sed -E 's|postgresql\+asyncpg://[^:]+:[^@]+@[^:/]+:?[0-9]*/([^?]+).*|\1|')
          postgres_user=$(echo "$database_url" | sed -E 's|postgresql\+asyncpg://([^:]+):.*|\1|')
          postgres_password=$(echo "$secrets" | jq -r '.POSTGRES_PASSWORD')
          postgres_port=$(echo "$database_url" | sed -E 's|postgresql\+asyncpg://[^:]+:[^@]+@[^:/]+:?([0-9]+)?/.*|\1|')
          if [ -z "$postgres_port" ]; then
              postgres_port="5432"
          fi
          # Validate extracted components
          for var in postgres_host postgres_db postgres_user postgres_password; do
            if [ -z "${!var}" ]; then
              echo "❌ Failed to extract $var from DATABASE_URL"
              exit 1
            fi
          done
          
          # Additional secrets extraction
          redis_url=$(echo "$secrets" | jq -r '.REDIS_URL')
          redis_db=$(echo "$secrets" | jq -r '.REDIS_DB // "0"')
          redis_host=$(echo "$redis_url" | sed -E 's|redis://(:[^@]+@)?([^:]+):?.*|\2|')
          redis_port=$(echo "$redis_url" | sed -E 's|redis://([^:]+@)?[^:]+:([0-9]+).*|\2|')
          #redis_password=$(echo "$redis_url" | sed -E 's|redis://:([^@]+)@.*|\1|')
          redis_password=""
          if [ -z "$redis_port" ]; then
              redis_port="6379"
          fi
          if [ -z "$redis_host" ]; then
              redis_host="localhost"
          fi

          bedrock_model_id=$(echo "$secrets" | jq -r '.BEDROCK_MODEL_ID')
          aws_bedrock_region=$(echo "$secrets" | jq -r '.AWS_BEDROCK_REGION')
          
          github_username=$(echo "$secrets" | jq -r '.GITHUB_USERNAME')
          github_token=$(echo "$secrets" | jq -r '.GITHUB_TOKEN')

          # Mask sensitive values
          echo "::add-mask::$database_url"
          echo "::add-mask::$postgres_host"
          echo "::add-mask::$postgres_port"
          echo "::add-mask::$postgres_db"
          echo "::add-mask::$postgres_user"
          echo "::add-mask::$postgres_password"
          echo "::add-mask::$github_username"
          echo "::add-mask::$github_token"

          # Output to GitHub Actions environment
          echo "DATABASE_URL=$database_url" >> $GITHUB_OUTPUT
          echo "POSTGRES_HOST=$postgres_host" >> $GITHUB_OUTPUT
          echo "POSTGRES_PORT=$postgres_port" >> $GITHUB_OUTPUT
          echo "POSTGRES_DB=$postgres_db" >> $GITHUB_OUTPUT
          echo "POSTGRES_USER=$postgres_user" >> $GITHUB_OUTPUT
          echo "POSTGRES_PASSWORD=$postgres_password" >> $GITHUB_OUTPUT
          
          echo "REDIS_URL=$redis_url" >> $GITHUB_OUTPUT
          echo "REDIS_HOST=$redis_host" >> $GITHUB_OUTPUT
          echo "REDIS_PORT=$redis_port" >> $GITHUB_OUTPUT
          echo "REDIS_DB=$redis_db" >> $GITHUB_OUTPUT
          echo "REDIS_PASSWORD=$redis_password" >> $GITHUB_OUTPUT
          
          echo "BEDROCK_MODEL_ID=$bedrock_model_id" >> $GITHUB_OUTPUT
          echo "AWS_BEDROCK_REGION=$aws_bedrock_region" >> $GITHUB_OUTPUT
          
          echo "GITHUB_USERNAME=$github_username" >> $GITHUB_OUTPUT
          echo "GITHUB_TOKEN=$github_token" >> $GITHUB_OUTPUT

      - name: Prepare Deployment Configuration
        env:
          # Secrets from AWS
          GITHUB_USERNAME: ${{ steps.get-secrets.outputs.GITHUB_USERNAME }}
          GITHUB_TOKEN: ${{ steps.get-secrets.outputs.GITHUB_TOKEN }}

          DATABASE_URL: ${{ steps.get-secrets.outputs.DATABASE_URL }}
          POSTGRES_HOST: ${{ steps.get-secrets.outputs.POSTGRES_HOST }}
          POSTGRES_PORT: ${{ steps.get-secrets.outputs.POSTGRES_PORT }}
          POSTGRES_DB: ${{ steps.get-secrets.outputs.POSTGRES_DB }}
          POSTGRES_USER: ${{ steps.get-secrets.outputs.POSTGRES_USER }}
          POSTGRES_PASSWORD: ${{ steps.get-secrets.outputs.POSTGRES_PASSWORD }}
          POSTGRES_DATA_DIR: ${{ inputs.postgres_data_dir }}

          REDIS_URL: ${{ steps.get-secrets.outputs.REDIS_URL }}
          REDIS_HOST: ${{ steps.get-secrets.outputs.REDIS_HOST }}
          REDIS_PORT: ${{ steps.get-secrets.outputs.REDIS_PORT }}
          REDIS_DB: ${{ steps.get-secrets.outputs.REDIS_DB }}
          REDIS_PASSWORD: ${{ steps.get-secrets.outputs.REDIS_PASSWORD }}
          
          BEDROCK_MODEL_ID: ${{ steps.get-secrets.outputs.BEDROCK_MODEL_ID }}
          AWS_BEDROCK_REGION: ${{ steps.get-secrets.outputs.AWS_BEDROCK_REGION }}
        run: |
          # Start with .env.example as base configuration
          cp .env.example .env
          
          # Override .env with secret values, preserving other parameters
          sed -i "s|^DATABASE_URL=.*|DATABASE_URL=$DATABASE_URL|" .env
          sed -i "s|^POSTGRES_HOST=.*|POSTGRES_HOST=$POSTGRES_HOST|" .env
          sed -i "s|^POSTGRES_PORT=.*|POSTGRES_PORT=$POSTGRES_PORT|" .env
          sed -i "s|^POSTGRES_DB=.*|POSTGRES_DB=$POSTGRES_DB|" .env
          sed -i "s|^POSTGRES_USER=.*|POSTGRES_USER=$POSTGRES_USER|" .env
          sed -i "s|^POSTGRES_PASSWORD=.*|POSTGRES_PASSWORD=$POSTGRES_PASSWORD|" .env
          
          sed -i "s|^REDIS_URL=.*|REDIS_URL=$REDIS_URL|" .env
          sed -i "s|^REDIS_HOST=.*|REDIS_HOST=$REDIS_HOST|" .env
          sed -i "s|^REDIS_PORT=.*|REDIS_PORT=$REDIS_PORT|" .env
          sed -i "s|^REDIS_DB=.*|REDIS_DB=$REDIS_DB|" .env
          sed -i "s|^REDIS_PASSWORD=.*|REDIS_PASSWORD=$REDIS_PASSWORD|" .env
          sed -i "s|^POSTGRES_DATA_DIR=.*|POSTGRES_DATA_DIR=$POSTGRES_DATA_DIR|" .env

          sed -i "s|^BEDROCK_MODEL_ID=.*|BEDROCK_MODEL_ID=$BEDROCK_MODEL_ID|" .env
          sed -i "s|^AWS_BEDROCK_REGION=.*|AWS_BEDROCK_REGION=$AWS_BEDROCK_REGION|" .env

          # Additional Fixed Configuration
          sed -i "s|^DEPLOYMENT_MODE=.*|DEPLOYMENT_MODE=production|" .env
          sed -i "s|^AWS_REGION=.*|AWS_REGION=us-east-1|" .env
          sed -i "s|^SERVER_HOST=.*|SERVER_HOST=0.0.0.0|" .env
          sed -i "s|^SERVER_PORT=.*|SERVER_PORT=8081|" .env
          
          # Secure .env file permissions
          chmod 600 .env

          # Validate .env file creation
          if [ ! -f .env ]; then
            cp .env.example .env
            echo "Created .env file from .env.example"
          fi
      
      # Configuration Validation
      - name: Run configuration validator
        run: |
          python config_validator.py .env
        env:
          DEPLOYMENT_MODE: production
          AWS_DEFAULT_REGION: us-east-1
          PYTHONPATH: .

      - name: Prepare SSH Key
        env:
          EC2_SSH_KEY: ${{ secrets.EC2_SSH_PRIVATE_KEY }}
        run: |
          if [ -z "$EC2_SSH_KEY" ]; then
            echo "EC2 SSH key is not set"
            exit 1
          fi
          
          mkdir -p ~/.ssh
          echo "$EC2_SSH_KEY" > ~/.ssh/ec2_key
          chmod 600 ~/.ssh/ec2_key
  
      - name: Cleanup Existing Deployments
        env:
          EC2_SSH_KEY: ${{ secrets.EC2_SSH_PRIVATE_KEY }}
          EC2_HOST: ${{ secrets.EC2_HOST }}
          EC2_USER: ${{ secrets.EC2_USER }}

        run: |
          ssh_opts="-o BatchMode=yes -o StrictHostKeyChecking=no -o ConnectTimeout=10"
          
          ssh $ssh_opts -i ~/.ssh/ec2_key "$EC2_USER@$EC2_HOST" \
            "EC2_HOST='$EC2_HOST' \
            EC2_USER='$EC2_USER' \
            bash -s" << 'REMOTE_SCRIPT'   
            set -e

            echo "🧹 Performing cleanup..."
            sudo docker ps -q --filter 'name=amta-' | xargs -r docker stop; \
            sudo docker ps -aq --filter 'name=amta-' | xargs -r docker rm; \
            sudo docker volume ls -q --filter 'dangling=true' | xargs -r docker volume rm
          REMOTE_SCRIPT

      - name: Deploy to EC2
        env:
          EC2_SSH_KEY: ${{ secrets.EC2_SSH_PRIVATE_KEY }}
          EC2_HOST: ${{ secrets.EC2_HOST }}
          EC2_USER: ${{ secrets.EC2_USER }}
          BEDROCK_MODEL_ID: ${{ steps.get-secrets.outputs.BEDROCK_MODEL_ID }}
          GITHUB_USERNAME: ${{ steps.get-secrets.outputs.GITHUB_USERNAME }}
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          FRONTEND_TAG: ${{ env.FRONTEND_TAG }}
          BACKEND_TAG: ${{ env.BACKEND_TAG }}
      
        run: |
          SSH_OPTS="-o BatchMode=yes -o StrictHostKeyChecking=no"

          # Setup EC2 environment
          ssh $SSH_OPTS -i ~/.ssh/ec2_key $EC2_USER@$EC2_HOST << SETUP_EOF
            HOME_DIR=\$(eval echo ~$EC2_USER)
            mkdir -p \$HOME_DIR/amta/logs
            chmod 750 \$HOME_DIR/amta/logs
            mkdir -p \$HOME_DIR/amta/next-app
            
            # Create lexical_values directory with subdirectories
            mkdir -p \$HOME_DIR/amta/lexical_values/current
            mkdir -p \$HOME_DIR/amta/lexical_values/versions
            mkdir -p \$HOME_DIR/amta/lexical_values/backup
            
            # Set permissions for lexical_values directory
            chmod 777 \$HOME_DIR/amta/lexical_values
            chmod 777 \$HOME_DIR/amta/lexical_values/current
            chmod 777 \$HOME_DIR/amta/lexical_values/versions
            chmod 777 \$HOME_DIR/amta/lexical_values/backup
            
            echo "Deployment initiated at \$(date)" > \$HOME_DIR/amta/logs/deployment.log
          SETUP_EOF

          # Copy deployment files
          scp $SSH_OPTS -i ~/.ssh/ec2_key \
            docker-compose.yml .env \
            $EC2_USER@$EC2_HOST:~/amta/

            # Make verification script executable
            chmod +x verify_deployment.sh

            # Login to GitHub Container Registry
          ssh $SSH_OPTS -i ~/.ssh/ec2_key "$EC2_USER@$EC2_HOST" \
            "GITHUB_USERNAME='$GITHUB_USERNAME' \
             GITHUB_TOKEN='$GITHUB_TOKEN' \
             FRONTEND_TAG='$FRONTEND_TAG' \
             BACKEND_TAG='$BACKEND_TAG' \
             bash -s" << 'REMOTE_SCRIPT'
              echo "Debug values:"
              echo "Username: $GITHUB_USERNAME"
              echo "Github Token: $GITHUB_TOKEN"
              echo "Frontend Tag: $FRONTEND_TAG"
              echo "Backend Tag: $BACKEND_TAG"
              
              echo "$GITHUB_TOKEN" | docker login ghcr.io -u "$GITHUB_USERNAME" --password-stdin
              
              HOME_DIR=$(eval echo ~$USER)
              cd $HOME_DIR/amta
              
              # Pull latest images
              FRONTEND_TAG="$FRONTEND_TAG" BACKEND_TAG="$BACKEND_TAG" docker-compose pull
              
              # Stop and remove existing containers
              docker-compose down || true
              
              # Start new deployment
              FRONTEND_TAG="$FRONTEND_TAG" BACKEND_TAG="$BACKEND_TAG" docker-compose up -d
              
              # Log container status
              docker-compose ps
              docker-compose logs --tail=100
          REMOTE_SCRIPT

      - name: Verify Deployment Health
        env:
          EC2_SSH_KEY: ${{ secrets.EC2_SSH_PRIVATE_KEY }}
          EC2_HOST: ${{ secrets.EC2_HOST }}
          EC2_USER: ${{ secrets.EC2_USER }}
          FRONTEND_TAG: ${{ env.FRONTEND_TAG }}
          BACKEND_TAG: ${{ env.BACKEND_TAG }}

        run: |
          SSH_OPTS="-o BatchMode=yes -o StrictHostKeyChecking=no"
          
          ssh $SSH_OPTS -i ~/.ssh/ec2_key $EC2_USER@$EC2_HOST\
            "FRONTEND_TAG='$FRONTEND_TAG' BACKEND_TAG='$BACKEND_TAG' bash -s" << HEALTH_EOF
            HOME_DIR=\$(eval echo ~$EC2_USER)
            cd \$HOME_DIR/amta
            
            # Create logs directory on EC2
            mkdir -p deployment_logs

            # Color codes for better visibility
            GREEN='\033[0;32m'
            YELLOW='\033[1;33m'
            RED='\033[0;31m'
            NC='\033[0m'

            max_attempts=3
            attempt=0
            
            # Quick check if containers are running
            echo -e "\${YELLOW}Checking Docker containers status...${NC}"
            FRONTEND_TAG=$FRONTEND_TAG BACKEND_TAG=$BACKEND_TAG docker-compose ps
            
            # Log initial container state
            echo "Initial Container Status at \$(date)" > deployment_logs/container_status.log
            FRONTEND_TAG=$FRONTEND_TAG BACKEND_TAG=$BACKEND_TAG docker-compose ps >> deployment_logs/container_status.log
            
            while [ \$attempt -lt \$max_attempts ]; do
              echo "Health Check Attempt \$((attempt + 1))" >> deployment_logs/health_checks.log
              
              backend_response=\$(curl -s -w "%{http_code}" http://localhost:8081/health)
              frontend_response=\$(curl -s -w "%{http_code}" http://localhost:3000)
              
              backend_status=\${backend_response: -3}
              frontend_status=\${frontend_response: -3}
              
              if [ "\$backend_status" = "200" ] && [ "\$frontend_status" = "200" ]; then
                echo -e "\${GREEN}Successful Health Check: Both Backend and Frontend are Operational${NC}"
                echo "Health Check Successful at \$(date)" >> deployment_logs/health_checks.log
                docker-compose logs > deployment_logs/successful_deployment.log

                # Log successful deployment version
                echo "Deployed versions:"
                echo "Frontend: \$(FRONTEND_TAG=$FRONTEND_TAG BACKEND_TAG=$BACKEND_TAG docker-compose ps frontend | grep -o 'frontend:.*')"
                echo "Backend: \$(FRONTEND_TAG=$FRONTEND_TAG BACKEND_TAG=$BACKEND_TAG docker-compose ps backend | grep -o 'backend:.*')"
                exit 0
              fi

              echo -e "\${RED}Health Check Failed. Backend Status: \$backend_status, Frontend Status: \$frontend_status${NC}"
              echo "Health Check Failed at \$(date)" >> deployment_logs/health_checks.log
              echo "Backend Status: \$backend_status" >> deployment_logs/health_checks.log
              echo "Frontend Status: \$frontend_status" >> deployment_logs/health_checks.log

              # More detailed failure information
              echo "Container Status:"
              FRONTEND_TAG=$FRONTEND_TAG BACKEND_TAG=$BACKEND_TAG docker-compose ps

              
              echo "Recent Logs:"
              docker-compose logs --tail=100
              
              # Check container resource usage
              echo "Container Resources:"
              docker stats --no-stream
              
              # Capture logs
              docker-compose logs > deployment_logs/attempt_\${attempt}_logs.log
              docker stats --no-stream > deployment_logs/attempt_\${attempt}_stats.log
              
              attempt=\$((attempt + 1))
              
              if [ \$attempt -lt \$max_attempts ]; then
                echo -e "\${YELLOW}Waiting 15 seconds before next attempt...${NC}"
                sleep 15
              fi
            done
            
            echo -e "\${RED}Critical: Health Checks Failed After \$max_attempts Attempts${NC}"
            # Collect additional debugging information
            echo "Full container logs:"
            docker-compose logs > deployment_failure.log
            
            # Capture final state on failure
            echo "Final Container Status at \$(date)" > deployment_logs/final_status.log
            FRONTEND_TAG=$FRONTEND_TAG BACKEND_TAG=$BACKEND_TAG docker-compose ps >> deployment_logs/final_status.log
            docker-compose logs > deployment_logs/final_logs.log
            
            # Create a tar of all logs
            tar -czf deployment_logs.tar.gz deployment_logs/
            exit 1
          HEALTH_EOF

          # Copy logs from EC2 if they exist
          scp $SSH_OPTS -i ~/.ssh/ec2_key \
              $EC2_USER@$EC2_HOST:~/amta/deployment_logs/* \
              deployment_logs/ || true
              
          if [ $? -ne 0 ]; then
            echo "::error::Deployment health check failed"
            exit 1
          fi

      - name: Preserve Deployment Logs
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: deployment-logs
          path: |
            deployment_logs/
            ${{ github.workspace }}/deployment_logs/
          retention-days: 7

      - name: Generate Fallback Logs
        if: failure()
        run: |
          mkdir -p deployment_logs
          echo "Workflow Failed" > deployment_logs/workflow_failure.log
          echo "Workflow Run ID: ${{ github.run_id }}" >> deployment_logs/workflow_failure.log
          echo "Repository: ${{ github.repository }}" >> deployment_logs/workflow_failure.log
          env >> deployment_logs/environment_vars.log

  notify-status:
    if: always()
    needs: [deploy-to-ec2]
    runs-on: ubuntu-latest
    steps:
      - name: Determine Workflow Status
        run: |
          if [[ "${{ needs.deploy-to-ec2.result }}" == "success" ]]; then
            echo "✅ Production Deployment Completed Successfully"
          else
            echo "❌ Production Deployment Failed"
            exit 1
          fi
