name: Database Restoration Workflow

on:
  workflow_dispatch:
    inputs:
      deployment_mode:
        description: 'Deployment mode (development/production)'
        required: false
        default: 'production'
      force_restore:
        description: 'Force database restoration'
        type: boolean
        default: false
      s3_backup_bucket:
        description: 'S3 Bucket for Database Backups'
        required: true
        default: 'amta-app'
      s3_backup_prefix:
        description: 'S3 Prefix for Database Backups'
        required: true
        default: 'amta-db'

permissions:
  id-token: write
  contents: read

jobs:
  database-restoration:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4

      - name: Configure AWS Credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: ${{ secrets.AWS_OIDC_ROLE_ARN }}
          aws-region: us-east-1

      - name: Retrieve Database Secrets
        id: get-database-secrets
        run: |
          secrets=$(aws secretsmanager get-secret-value --secret-id amta-production-secrets --query SecretString --output text)
          
          database_url=$(echo "$secrets" | jq -r '.DATABASE_URL')
          postgres_host=$(echo "$database_url" | sed -E 's|postgresql\+asyncpg://[^:]+:[^@]+@([^:/]+).*|\1|')
          postgres_port=$(echo "$database_url" | sed -E 's|postgresql\+asyncpg://[^:]+:[^@]+@[^:/]+:?([0-9]+)?.*|\1|' || echo "5432")
          postgres_db=$(echo "$database_url" | sed -E 's|postgresql\+asyncpg://[^:]+:[^@]+@[^:/]+:?[0-9]*/([^?]+).*|\1|')
          postgres_user=$(echo "$database_url" | sed -E 's|postgresql\+asyncpg://([^:]+):.*|\1|')
          postgres_password=$(echo "$secrets" | jq -r '.POSTGRES_PASSWORD')

          echo "POSTGRES_HOST=$postgres_host" >> $GITHUB_OUTPUT
          echo "POSTGRES_PORT=$postgres_port" >> $GITHUB_OUTPUT
          echo "POSTGRES_DB=$postgres_db" >> $GITHUB_OUTPUT
          echo "POSTGRES_USER=$postgres_user" >> $GITHUB_OUTPUT
          echo "POSTGRES_PASSWORD=$postgres_password" >> $GITHUB_OUTPUT

          echo "üîç Database Connection Details:"
          echo "  Host: $postgres_host"
          echo "  Port: $postgres_port"
          echo "  Database: $postgres_db"
          echo "  User: $postgres_user"

      - name: Check Database Connectivity
        id: database-connectivity
        env:
          POSTGRES_HOST: ${{ steps.get-database-secrets.outputs.POSTGRES_HOST }}
          POSTGRES_PORT: ${{ steps.get-database-secrets.outputs.POSTGRES_PORT }}
          POSTGRES_DB: ${{ steps.get-database-secrets.outputs.POSTGRES_DB }}
          POSTGRES_USER: ${{ steps.get-database-secrets.outputs.POSTGRES_USER }}
          POSTGRES_PASSWORD: ${{ steps.get-database-secrets.outputs.POSTGRES_PASSWORD }}
        run: |
          export PGPASSWORD=$POSTGRES_PASSWORD
          
          echo "üîå Attempting Database Connection:"
          echo "  Host: $POSTGRES_HOST"
          echo "  Port: $POSTGRES_PORT"
          echo "  Database: $POSTGRES_DB"
          echo "  User: $POSTGRES_USER"

          # Attempt connection with timeout
          connection_output=$(timeout 10s psql -h "$POSTGRES_HOST" -p "$POSTGRES_PORT" -U "$POSTGRES_USER" -d "$POSTGRES_DB" -t -c "SELECT 1" 2>&1)
          connection_status=$?
          
          if [ $connection_status -eq 0 ]; then
            echo "‚úÖ Database connection successful"
            echo "connection_status=success" >> $GITHUB_OUTPUT
            echo "connection_available=true" >> $GITHUB_OUTPUT
          else
            echo "‚ùå Database connection failed"
            echo "Connection Error: $connection_output"
            echo "connection_status=failed" >> $GITHUB_OUTPUT
            echo "connection_available=false" >> $GITHUB_OUTPUT
          fi
          
          # Always continue workflow
          exit 0

      - name: Check PostgreSQL Data Directory
        id: check-postgres-data
        if: steps.database-connectivity.outputs.connection_available == 'false'
        env:
          EC2_HOST: ${{ secrets.EC2_HOST }}
          EC2_USER: ${{ secrets.EC2_USER }}
        run: |
          SSH_OPTS="-o BatchMode=yes -o StrictHostKeyChecking=no"
          
          # Check PostgreSQL data directory
          ssh $SSH_OPTS -i ~/.ssh/ec2_key $EC2_USER@$EC2_HOST << REMOTE_SCRIPT
            # Check if data directory exists
            if [ -d "/var/lib/postgresql/data" ]; then
              # Count files in the directory
              file_count=$(find /var/lib/postgresql/data -type f | wc -l)
              
              if [ "\$file_count" -gt 0 ]; then
                echo "‚úÖ PostgreSQL data directory exists and contains files"
                exit 0
              else
                echo "‚ö†Ô∏è PostgreSQL data directory is empty"
                exit 1
              fi
            else
              echo "‚ùå PostgreSQL data directory does not exist"
              exit 2
            fi
          REMOTE_SCRIPT
          
          case $? in
            0)
              echo "postgres_data_status=populated" >> $GITHUB_OUTPUT
              ;;
            1)
              echo "postgres_data_status=empty" >> $GITHUB_OUTPUT
              ;;
            2)
              echo "postgres_data_status=missing" >> $GITHUB_OUTPUT
              ;;
          esac

      - name: Check Backup File Availability
        id: check-backup-file
        if: steps.check-postgres-data.outputs.postgres_data_status == 'missing' || steps.check-postgres-data.outputs.postgres_data_status == 'empty'
        env:
          EC2_HOST: ${{ secrets.EC2_HOST }}
          EC2_USER: ${{ secrets.EC2_USER }}
        run: |
          SSH_OPTS="-o BatchMode=yes -o StrictHostKeyChecking=no"
          
          # Check backup file in /opt/atlomy/database_backups
          ssh $SSH_OPTS -i ~/.ssh/ec2_key $EC2_USER@$EC2_HOST << REMOTE_SCRIPT
            # Ensure backup directory exists
            mkdir -p /opt/atlomy/database_backups
            
            # Check for backup file
            if [ -f "/opt/atlomy/database_backups/latest_backup.tar.gz" ]; then
              echo "‚úÖ Backup file exists in /opt/atlomy/database_backups"
              exit 0
            else
              echo "‚ùå No backup file in /opt/atlomy/database_backups"
              exit 1
            fi
          REMOTE_SCRIPT
          
          if [ $? -eq 0 ]; then
            echo "backup_file_status=exists" >> $GITHUB_OUTPUT
          else
            echo "backup_file_status=missing" >> $GITHUB_OUTPUT
          fi

      - name: Download Backup from S3
        id: download-backup
        if: steps.check-backup-file.outputs.backup_file_status == 'missing'
        env:
          S3_BACKUP_BUCKET: ${{ inputs.s3_backup_bucket || 'amta-app' }}
          S3_BACKUP_PREFIX: ${{ inputs.s3_backup_prefix || 'amta-db' }}
          EC2_HOST: ${{ secrets.EC2_HOST }}
          EC2_USER: ${{ secrets.EC2_USER }}
        run: |
          echo "üìã Discovering Latest Backup"
          latest_backup=$(aws s3 ls "s3://$S3_BACKUP_BUCKET/$S3_BACKUP_PREFIX/" | grep '.tar.gz' | sort | tail -n 1 | awk '{print $4}')
          
          if [ -z "$latest_backup" ]; then
            echo "‚ùå Error: No backup files found in S3 bucket"
            exit 1
          fi

          echo "üè∑Ô∏è Latest Backup: $latest_backup"
          
          SSH_OPTS="-o BatchMode=yes -o StrictHostKeyChecking=no"
          
          # Transfer backup to EC2
          ssh $SSH_OPTS -i ~/.ssh/ec2_key $EC2_USER@$EC2_HOST << REMOTE_SCRIPT
            mkdir -p /opt/atlomy/database_backups
            aws s3 cp "s3://$S3_BACKUP_BUCKET/$S3_BACKUP_PREFIX/$latest_backup" /opt/atlomy/database_backups/latest_backup.tar.gz
            
            # Verify download
            if [ -f "/opt/atlomy/database_backups/latest_backup.tar.gz" ]; then
              echo "‚úÖ Backup downloaded successfully"
              exit 0
            else
              echo "‚ùå Backup download failed"
              exit 1
            fi
          REMOTE_SCRIPT
          
          if [ $? -eq 0 ]; then
            echo "download_status=success" >> $GITHUB_OUTPUT
          else
            echo "download_status=failed" >> $GITHUB_OUTPUT
            exit 1
          fi

      - name: Restore PostgreSQL Database
        if: steps.download-backup.outputs.download_status == 'success'
        env:
          POSTGRES_HOST: ${{ steps.get-database-secrets.outputs.POSTGRES_HOST }}
          POSTGRES_DB: ${{ steps.get-database-secrets.outputs.POSTGRES_DB }}
          POSTGRES_USER: ${{ steps.get-database-secrets.outputs.POSTGRES_USER }}
          POSTGRES_PASSWORD: ${{ steps.get-database-secrets.outputs.POSTGRES_PASSWORD }}
          EC2_HOST: ${{ secrets.EC2_HOST }}
          EC2_USER: ${{ secrets.EC2_USER }}
        run: |
          SSH_OPTS="-o BatchMode=yes -o StrictHostKeyChecking=no"
          
          ssh $SSH_OPTS -i ~/.ssh/ec2_key $EC2_USER@$EC2_HOST << EOF
            export PGPASSWORD=$POSTGRES_PASSWORD
            
            # Restore backup
            pg_restore -h "$POSTGRES_HOST" -U "$POSTGRES_USER" -d "$POSTGRES_DB" /opt/atlomy/database_backups/latest_backup.tar.gz
            
            # Verify restoration
            table_count=$(psql -h "$POSTGRES_HOST" -U "$POSTGRES_USER" -d "$POSTGRES_DB" -t -c "SELECT COUNT(*) FROM information_schema.tables WHERE table_schema = 'public';")
            
            if [ "\$table_count" -eq 0 ]; then
              echo "‚ùå Database restoration failed: No tables found"
              exit 1
            fi
            
            echo "‚úÖ Database restored successfully. Tables found: \$table_count"
          EOF

  notify-status:
    if: always()
    needs: [database-restoration]
    runs-on: ubuntu-latest
    steps:
      - name: Determine Workflow Status
        run: |
          if [[ "${{ needs.database-restoration.result }}" == "success" ]]; then
            echo "‚úÖ Database Restoration Completed Successfully"
          else
            echo "‚ùå Database Restoration Failed"
            exit 1
          fi
