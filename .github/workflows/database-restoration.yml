name: Database Restoration Workflow

on:
  workflow_dispatch:
    inputs:
      deployment_mode:
        description: 'Deployment mode (development/production)'
        required: false
        default: 'production'
      force_restore:
        description: 'Force database restoration'
        type: boolean
        default: false
      s3_backup_bucket:
        description: 'S3 Bucket for Database Backups'
        required: true
        default: 'amta-app'
      s3_backup_prefix:
        description: 'S3 Prefix for Database Backups'
        required: true
        default: 'amta-db'
  workflow_call:
    inputs:
      deployment_mode:
        description: 'Deployment mode (development/production)'
        type: string
        required: false
        default: 'production'
      force_restore:
        description: 'Force database restoration'
        type: boolean
        default: false
      s3_backup_bucket:
        description: 'S3 Bucket for Database Backups'
        type: string
        required: false
        default: 'amta-app'
      s3_backup_prefix:
        description: 'S3 Prefix for Database Backups'
        type: string
        required: false
        default: 'amta-db'

permissions:
  id-token: write
  contents: read

jobs:
  pre-restore-checks:
    runs-on: ubuntu-latest
    outputs:
      should_restore: ${{ steps.check-conditions.outputs.should_restore }}
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Check Restoration Conditions
        id: check-conditions
        env:
          FORCE_RESTORE: ${{ inputs.force_restore || github.event.inputs.force_restore }}
          DEPLOYMENT_MODE: ${{ inputs.deployment_mode || github.event.inputs.deployment_mode || 'production' }}
          S3_BACKUP_BUCKET: ${{ inputs.s3_backup_bucket || 'amta-app' }}
          S3_BACKUP_PREFIX: ${{ inputs.s3_backup_prefix || 'amta-db' }}
        run: |
          echo "üîç Analyzing Restoration Conditions"
          echo "Deployment Mode: $DEPLOYMENT_MODE"
          echo "Force Restore: $FORCE_RESTORE"
          echo "S3 Backup Bucket: $S3_BACKUP_BUCKET"
          echo "S3 Backup Prefix: $S3_BACKUP_PREFIX"
          
          if [[ "$FORCE_RESTORE" == "true" ]]; then
            echo "‚úÖ Force restore enabled"
            echo "should_restore=true" >> $GITHUB_OUTPUT
          else
            echo "‚úÖ Standard restoration conditions met"
            echo "should_restore=true" >> $GITHUB_OUTPUT
          fi

  database-restoration:
    needs: pre-restore-checks
    if: needs.pre-restore-checks.outputs.should_restore == 'true'
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Configure AWS Credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: ${{ secrets.AWS_OIDC_ROLE_ARN }}
          aws-region: us-east-1

      - name: Retrieve Database Secrets
        id: get-database-secrets
        run: |
          secrets=$(aws secretsmanager get-secret-value --secret-id amta-production-secrets --query SecretString --output text)
          
          # Extract DATABASE_URL and parse host
          database_url=$(echo $secrets | jq -r '.DATABASE_URL')
          postgres_user=$(echo $secrets | jq -r '.POSTGRES_USER')
          postgres_password=$(echo $secrets | jq -r '.POSTGRES_PASSWORD')
          
          # Parse host from DATABASE_URL using sed
          postgres_host=$(echo "$database_url" | sed -E 's|postgresql\+asyncpg://[^:]+:[^@]+@([^:/]+).*|\1|')
          postgres_port=$(echo "$database_url" | sed -E 's|postgresql\+asyncpg://[^:]+:[^@]+@[^:/]+:?([0-9]+)?.*|\1|' || echo "5432")
          postgres_db=$(echo "$database_url" | sed -E 's|postgresql\+asyncpg://[^:]+:[^@]+@[^:/]+:?[0-9]*/(.+)|\1|')
          
          # Validate parsed values
          if [ -z "$postgres_host" ] || [ -z "$postgres_db" ] || [ -z "$postgres_user" ] || [ -z "$postgres_password" ]; then
            echo "‚ùå Failed to parse database connection details"
            echo "Parsed Host: $postgres_host, Database: $postgres_db, User: $postgres_user"
            exit 1
          fi
          
          echo "POSTGRES_HOST=$postgres_host" >> $GITHUB_OUTPUT
          echo "POSTGRES_PORT=$postgres_port" >> $GITHUB_OUTPUT
          echo "POSTGRES_DB=$postgres_db" >> $GITHUB_OUTPUT
          echo "POSTGRES_USER=$postgres_user" >> $GITHUB_OUTPUT
          echo "POSTGRES_PASSWORD=$postgres_password" >> $GITHUB_OUTPUT

      - name: Check Existing Database State
        id: database-check
        env:
          POSTGRES_HOST: ${{ steps.get-database-secrets.outputs.POSTGRES_HOST }}
          POSTGRES_DB: ${{ steps.get-database-secrets.outputs.POSTGRES_DB }}
          POSTGRES_USER: ${{ steps.get-database-secrets.outputs.POSTGRES_USER }}
          POSTGRES_PASSWORD: ${{ steps.get-database-secrets.outputs.POSTGRES_PASSWORD }}
        run: |
          export PGPASSWORD=$POSTGRES_PASSWORD
          
          # Check if database exists
          db_exists=$(psql -h "$POSTGRES_HOST" -U "$POSTGRES_USER" -t -c "SELECT 1 FROM pg_database WHERE datname = '$POSTGRES_DB'")
          
          # If database doesn't exist, we need to restore
          if [ -z "$db_exists" ]; then
            echo "‚ùå Database does not exist"
            echo "restore_needed=true" >> $GITHUB_OUTPUT
            exit 0
          fi
          
          # Check current database checksum
          current_checksum=$(psql -h "$POSTGRES_HOST" -U "$POSTGRES_USER" -d "$POSTGRES_DB" -t -c "SELECT md5(string_agg(md5(row::text), '')) FROM (SELECT * FROM information_schema.tables LIMIT 1000) AS row")
          
          echo "current_checksum=$current_checksum" >> $GITHUB_OUTPUT
          echo "‚úÖ Database checksum retrieved"

      - name: Find Latest Database Backup
        id: find-backup
        if: steps.database-check.outputs.restore_needed == 'true'
        env:
          S3_BACKUP_BUCKET: ${{ inputs.s3_backup_bucket || 'amta-app' }}
          S3_BACKUP_PREFIX: ${{ inputs.s3_backup_prefix || 'amta-db' }}
        run: |
          echo "üìã Discovering Latest Backup"
          latest_backup=$(aws s3 ls "s3://$S3_BACKUP_BUCKET/$S3_BACKUP_PREFIX/" | grep '.tar.gz' | sort | tail -n 1 | awk '{print $4}')
          
          if [ -z "$latest_backup" ]; then
            echo "‚ùå Error: No backup files found in S3 bucket"
            exit 1
          fi

          echo "üè∑Ô∏è Latest Backup: $latest_backup"
          echo "backup_file=$latest_backup" >> $GITHUB_OUTPUT

      - name: Download and Validate Backup
        id: download-backup
        if: steps.database-check.outputs.restore_needed == 'true'
        env:
          S3_BACKUP_BUCKET: ${{ inputs.s3_backup_bucket || 'amta-app' }}
          S3_BACKUP_PREFIX: ${{ inputs.s3_backup_prefix || 'amta-db' }}
          BACKUP_FILE: ${{ steps.find-backup.outputs.backup_file }}
        run: |
          echo "‚¨áÔ∏è Downloading Backup: $BACKUP_FILE"
          aws s3 cp "s3://$S3_BACKUP_BUCKET/$S3_BACKUP_PREFIX/$BACKUP_FILE" ./latest_backup.tar.gz

          if [ ! -f ./latest_backup.tar.gz ]; then
            echo "‚ùå Error: Backup download failed"
            exit 1
          fi

          backup_size=$(du -h ./latest_backup.tar.gz | cut -f1)
          backup_checksum=$(sha256sum ./latest_backup.tar.gz | awk '{print $1}')

          echo "üì¶ Backup Size: $backup_size"
          echo "üî¢ Backup Checksum: $backup_checksum"

          echo "backup_size=$backup_size" >> $GITHUB_OUTPUT
          echo "backup_checksum=$backup_checksum" >> $GITHUB_OUTPUT

      - name: Determine Restore Necessity
        id: restore-decision
        env:
          CURRENT_CHECKSUM: ${{ steps.database-check.outputs.current_checksum }}
          BACKUP_CHECKSUM: ${{ steps.download-backup.outputs.backup_checksum }}
          DB_EXISTS: ${{ steps.database-check.outputs.restore_needed }}
        run: |
          if [[ "$DB_EXISTS" == "true" ]]; then
            echo "‚úÖ Database does not exist. Restore needed."
            echo "restore_needed=true" >> $GITHUB_OUTPUT
          elif [[ "$CURRENT_CHECKSUM" != "$BACKUP_CHECKSUM" ]]; then
            echo "üîÑ Database checksum differs. Restore needed."
            echo "restore_needed=true" >> $GITHUB_OUTPUT
          else
            echo "‚úÖ Database is up to date."
            echo "restore_needed=false" >> $GITHUB_OUTPUT
          fi

      - name: Prepare SSH Key
        if: steps.restore-decision.outputs.restore_needed == 'true'
        env:
          EC2_SSH_KEY: ${{ secrets.EC2_SSH_PRIVATE_KEY }}
        run: |
          echo "üîê Preparing SSH Key"
          mkdir -p ~/.ssh
          echo "$EC2_SSH_KEY" > ~/.ssh/ec2_key
          chmod 600 ~/.ssh/ec2_key
          echo "‚úÖ SSH Key prepared successfully"

      - name: Transfer Backup to EC2
        if: steps.restore-decision.outputs.restore_needed == 'true'
        env:
          S3_BACKUP_BUCKET: ${{ secrets.S3_BACKUP_BUCKET }}
          BACKUP_FILE: ${{ steps.find-backup.outputs.backup_file }}
          BACKUP_SIZE: ${{ steps.download-backup.outputs.backup_size }}
          EC2_HOST: ${{ secrets.EC2_HOST }}
          EC2_USER: ${{ secrets.EC2_USER }}
        run: |
          echo "üöÄ Transferring Backup to EC2"
          echo "üìç Destination: $EC2_USER@$EC2_HOST"
          echo "üì¶ Backup Size: $BACKUP_SIZE"

          SSH_OPTS="-o BatchMode=yes -o StrictHostKeyChecking=no -v"

          # Ensure remote backup directory exists with sudo
          ssh $SSH_OPTS -i ~/.ssh/ec2_key $EC2_USER@$EC2_HOST "sudo mkdir -p /opt/atlomy/database_backups && sudo chown $EC2_USER:$EC2_USER /opt/atlomy/database_backups"

          # Transfer backup with verbose output
          scp -v $SSH_OPTS -i ~/.ssh/ec2_key \
              ./latest_backup.tar.gz \
              $EC2_USER@$EC2_HOST:/opt/atlomy/database_backups/latest_backup.tar.gz

          echo "‚úÖ Backup transfer completed"

      - name: Restore PostgreSQL Database
        if: steps.restore-decision.outputs.restore_needed == 'true'
        env:
          EC2_HOST: ${{ secrets.EC2_HOST }}
          EC2_USER: ${{ secrets.EC2_USER }}
          POSTGRES_HOST: ${{ steps.get-database-secrets.outputs.POSTGRES_HOST }}
          POSTGRES_DB: ${{ steps.get-database-secrets.outputs.POSTGRES_DB }}
          POSTGRES_USER: ${{ steps.get-database-secrets.outputs.POSTGRES_USER }}
          POSTGRES_PASSWORD: ${{ steps.get-database-secrets.outputs.POSTGRES_PASSWORD }}
        run: |
          SSH_OPTS="-o BatchMode=yes -o StrictHostKeyChecking=no"
          
          ssh $SSH_OPTS -i ~/.ssh/ec2_key $EC2_USER@$EC2_HOST << EOF
            export PGPASSWORD=$POSTGRES_PASSWORD
            
            # Drop existing database if it exists
            psql -h "$POSTGRES_HOST" -U "$POSTGRES_USER" -c "DROP DATABASE IF EXISTS \"$POSTGRES_DB\";"
            
            # Create new database
            psql -h "$POSTGRES_HOST" -U "$POSTGRES_USER" -c "CREATE DATABASE \"$POSTGRES_DB\";"
            
            # Restore backup
            pg_restore -h "$POSTGRES_HOST" -U "$POSTGRES_USER" -d "$POSTGRES_DB" /opt/atlomy/database_backups/latest_backup.tar.gz
            
            # Verify restoration
            table_count=$(psql -h "$POSTGRES_HOST" -U "$POSTGRES_USER" -d "$POSTGRES_DB" -t -c "SELECT COUNT(*) FROM information_schema.tables WHERE table_schema = 'public';")
            
            if [ "\$table_count" -eq 0 ]; then
              echo "‚ùå Database restoration failed: No tables found"
              exit 1
            fi
            
            echo "‚úÖ Database restored successfully. Tables found: \$table_count"
          EOF

  notify-status:
    if: always()
    needs: [pre-restore-checks, database-restoration]
    runs-on: ubuntu-latest
    steps:
      - name: Determine Workflow Status
        run: |
          if [[ "${{ needs.database-restoration.result }}" == "success" ]]; then
            echo "‚úÖ Database Backup Staging Completed Successfully"
          else
            echo "‚ùå Database Backup Staging Failed"
            exit 1
          fi
