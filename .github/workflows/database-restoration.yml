name: Database Restoration Workflow

on:
  workflow_dispatch:
    inputs:
      deployment_mode:
        description: 'Deployment mode (development/production)'
        required: false
        default: 'production'
      force_restore:
        description: 'Force database restoration'
        type: boolean
        default: false
      s3_backup_bucket:
        description: 'S3 Bucket for Database Backups'
        required: true
        default: 'amta-app'
      s3_backup_prefix:
        description: 'S3 Prefix for Database Backups'
        required: true
        default: 'amta-db'

permissions:
  id-token: write
  contents: read

jobs:
  database-restoration:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4

      - name: Configure AWS Credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: ${{ secrets.AWS_OIDC_ROLE_ARN }}
          aws-region: us-east-1

      - name: Retrieve Database Secrets
        id: get-database-secrets
        run: |
          secrets=$(aws secretsmanager get-secret-value --secret-id amta-production-secrets --query SecretString --output text)
          
          database_url=$(echo "$secrets" | jq -r '.DATABASE_URL')
          postgres_host=$(echo "$database_url" | sed -E 's|postgresql\+asyncpg://[^:]+:[^@]+@([^:/]+).*|\1|')
          postgres_port=$(echo "$database_url" | sed -E 's|postgresql\+asyncpg://[^:]+:[^@]+@[^:/]+:?([0-9]+)?.*|\1|' || echo "5432")
          postgres_db=$(echo "$database_url" | sed -E 's|postgresql\+asyncpg://[^:]+:[^@]+@[^:/]+:?[0-9]*/([^?]+).*|\1|')
          postgres_user=$(echo "$database_url" | sed -E 's|postgresql\+asyncpg://([^:]+):.*|\1|')
          postgres_password=$(echo "$secrets" | jq -r '.POSTGRES_PASSWORD')

          echo "POSTGRES_HOST=$postgres_host" >> $GITHUB_OUTPUT
          echo "POSTGRES_PORT=$postgres_port" >> $GITHUB_OUTPUT
          echo "POSTGRES_DB=$postgres_db" >> $GITHUB_OUTPUT
          echo "POSTGRES_USER=$postgres_user" >> $GITHUB_OUTPUT
          echo "POSTGRES_PASSWORD=$postgres_password" >> $GITHUB_OUTPUT

          echo "ðŸ” Database Connection Details:"
          echo "  Host: $postgres_host"
          echo "  Port: $postgres_port"
          echo "  Database: $postgres_db"
          echo "  User: $postgres_user"

      - name: Prepare SSH Key
        run: |
          echo "ðŸ” Preparing SSH Key"
          mkdir -p ~/.ssh
          echo "${{ secrets.EC2_SSH_PRIVATE_KEY }}" > ~/.ssh/ec2_key
          chmod 600 ~/.ssh/ec2_key

      - name: Check Database Connectivity
        id: database-connectivity
        env:
          POSTGRES_HOST: ${{ steps.get-database-secrets.outputs.POSTGRES_HOST }}
          POSTGRES_PORT: ${{ steps.get-database-secrets.outputs.POSTGRES_PORT }}
          POSTGRES_DB: ${{ steps.get-database-secrets.outputs.POSTGRES_DB }}
          POSTGRES_USER: ${{ steps.get-database-secrets.outputs.POSTGRES_USER }}
          POSTGRES_PASSWORD: ${{ steps.get-database-secrets.outputs.POSTGRES_PASSWORD }}
        run: |
          export PGPASSWORD=$POSTGRES_PASSWORD
          
          echo "ðŸ”Œ Attempting Database Connection:"
          echo "  Host: $POSTGRES_HOST"
          echo "  Port: $POSTGRES_PORT"
          echo "  Database: $POSTGRES_DB"
          echo "  User: $POSTGRES_USER"

          # Attempt connection with timeout
          connection_output=$(timeout 10s psql -h "$POSTGRES_HOST" -p "$POSTGRES_PORT" -U "$POSTGRES_USER" -d "$POSTGRES_DB" -t -c "SELECT 1" 2>&1)
          connection_status=$?
          
          if [ $connection_status -eq 0 ]; then
            echo "âœ… Database connection successful"
            echo "connection_status=success" >> $GITHUB_OUTPUT
            echo "connection_available=true" >> $GITHUB_OUTPUT
          else
            echo "âŒ Database connection failed"
            echo "Connection Error: $connection_output"
            echo "connection_status=failed" >> $GITHUB_OUTPUT
            echo "connection_available=false" >> $GITHUB_OUTPUT
          fi
          
          # Always continue workflow
          exit 0

      - name: Check PostgreSQL Data Directory
        id: check-postgres-data
        env:
          EC2_HOST: ${{ secrets.EC2_HOST }}
          EC2_USER: ${{ secrets.EC2_USER }}
        run: |
          SSH_OPTS="-o BatchMode=yes -o StrictHostKeyChecking=no"
          
          # Check PostgreSQL data directory
          ssh $SSH_OPTS -i ~/.ssh/ec2_key $EC2_USER@$EC2_HOST << REMOTE_SCRIPT
            # Check if data directory exists
            if [ -d "/var/lib/postgresql/data" ]; then
              # Count files in the directory
              file_count=$(find /var/lib/postgresql/data -type f | wc -l)
              
              if [ "\$file_count" -gt 0 ]; then
                echo "âœ… PostgreSQL data directory exists and contains files"
                exit 0
              else
                echo "âš ï¸ PostgreSQL data directory is empty"
                exit 1
              fi
            else
              echo "âŒ PostgreSQL data directory does not exist"
              exit 2
            fi
          REMOTE_SCRIPT
          
          case $? in
            0)
              echo "postgres_data_status=populated" >> $GITHUB_OUTPUT
              ;;
            1)
              echo "postgres_data_status=empty" >> $GITHUB_OUTPUT
              ;;
            2)
              echo "postgres_data_status=missing" >> $GITHUB_OUTPUT
              ;;
          esac

      - name: Verify Backup Availability
        id: verify-backup
        env:
          S3_BACKUP_BUCKET: ${{ inputs.s3_backup_bucket || 'amta-app' }}
          S3_BACKUP_PREFIX: ${{ inputs.s3_backup_prefix || 'amta-db' }}
          EC2_HOST: ${{ secrets.EC2_HOST }}
          EC2_USER: ${{ secrets.EC2_USER }}
        run: |
          # Discover latest backup
          latest_backup=$(aws s3 ls "s3://$S3_BACKUP_BUCKET/$S3_BACKUP_PREFIX/" | grep '.tar.gz' | sort | tail -n 1 | awk '{print $4}')
          
          if [ -z "$latest_backup" ]; then
            echo "âŒ No backup files found in S3 bucket"
            echo "backup_available=false" >> $GITHUB_OUTPUT
            exit 1
          fi

          echo "ðŸ·ï¸ Latest Backup: $latest_backup"
          echo "backup_file=$latest_backup" >> $GITHUB_OUTPUT
          echo "backup_available=true" >> $GITHUB_OUTPUT

          # Check remote backup directory
          SSH_OPTS="-o BatchMode=yes -o StrictHostKeyChecking=no"
          
          ssh $SSH_OPTS -i ~/.ssh/ec2_key $EC2_USER@$EC2_HOST << REMOTE_SCRIPT
            # Ensure backup directory exists
            mkdir -p /opt/atlomy/database_backups
            
            # Check if backup already exists
            if [ -f "/opt/atlomy/database_backups/latest_backup.tar.gz" ]; then
              echo "âœ… Backup file already exists in remote directory"
              exit 0
            else
              echo "âŒ No backup file in remote directory"
              exit 1
            fi
          REMOTE_SCRIPT
          
          remote_backup_status=$?
          
          if [ $remote_backup_status -eq 0 ]; then
            echo "remote_backup_status=exists" >> $GITHUB_OUTPUT
          else
            echo "remote_backup_status=missing" >> $GITHUB_OUTPUT
          fi

      - name: Download Backup to Remote Host
        id: download-backup
        if: steps.verify-backup.outputs.remote_backup_status == 'missing'
        env:
          S3_BACKUP_BUCKET: ${{ inputs.s3_backup_bucket || 'amta-app' }}
          S3_BACKUP_PREFIX: ${{ inputs.s3_backup_prefix || 'amta-db' }}
          BACKUP_FILE: ${{ steps.verify-backup.outputs.backup_file }}
          EC2_HOST: ${{ secrets.EC2_HOST }}
          EC2_USER: ${{ secrets.EC2_USER }}
        run: |
          SSH_OPTS="-o BatchMode=yes -o StrictHostKeyChecking=no"
          
          # Transfer backup to remote host
          ssh $SSH_OPTS -i ~/.ssh/ec2_key $EC2_USER@$EC2_HOST << REMOTE_SCRIPT
            # Download backup from S3
            aws s3 cp "s3://$S3_BACKUP_BUCKET/$S3_BACKUP_PREFIX/$BACKUP_FILE" /opt/atlomy/database_backups/latest_backup.tar.gz
            
            # Verify download
            if [ -f "/opt/atlomy/database_backups/latest_backup.tar.gz" ]; then
              echo "âœ… Backup downloaded successfully"
              exit 0
            else
              echo "âŒ Backup download failed"
              exit 1
            fi
          REMOTE_SCRIPT
          
          if [ $? -eq 0 ]; then
            echo "download_status=success" >> $GITHUB_OUTPUT
          else
            echo "download_status=failed" >> $GITHUB_OUTPUT
            exit 1
          fi

      - name: Restore PostgreSQL Database
        if: steps.download-backup.outputs.download_status == 'success' || steps.verify-backup.outputs.remote_backup_status == 'exists'
        env:
          POSTGRES_HOST: ${{ steps.get-database-secrets.outputs.POSTGRES_HOST }}
          POSTGRES_DB: ${{ steps.get-database-secrets.outputs.POSTGRES_DB }}
          POSTGRES_USER: ${{ steps.get-database-secrets.outputs.POSTGRES_USER }}
          POSTGRES_PASSWORD: ${{ steps.get-database-secrets.outputs.POSTGRES_PASSWORD }}
          EC2_HOST: ${{ secrets.EC2_HOST }}
          EC2_USER: ${{ secrets.EC2_USER }}
        run: |
          SSH_OPTS="-o BatchMode=yes -o StrictHostKeyChecking=no"
          
          ssh $SSH_OPTS -i ~/.ssh/ec2_key $EC2_USER@$EC2_HOST << EOF
            export PGPASSWORD=$POSTGRES_PASSWORD
            
            # Drop existing database
            psql -h "$POSTGRES_HOST" -U "$POSTGRES_USER" -c "DROP DATABASE IF EXISTS \"$POSTGRES_DB\";"
            
            # Create new database
            psql -h "$POSTGRES_HOST" -U "$POSTGRES_USER" -c "CREATE DATABASE \"$POSTGRES_DB\";"
            
            # Restore backup
            pg_restore -h "$POSTGRES_HOST" -U "$POSTGRES_USER" -d "$POSTGRES_DB" /opt/atlomy/database_backups/latest_backup.tar.gz
            
            # Verify restoration
            table_count=$(psql -h "$POSTGRES_HOST" -U "$POSTGRES_USER" -d "$POSTGRES_DB" -t -c "SELECT COUNT(*) FROM information_schema.tables WHERE table_schema = 'public';")
            
            if [ "\$table_count" -eq 0 ]; then
              echo "âŒ Database restoration failed: No tables found"
              exit 1
            fi
            
            echo "âœ… Database restored successfully. Tables found: \$table_count"
          EOF

  notify-status:
    if: always()
    needs: [database-restoration]
    runs-on: ubuntu-latest
    steps:
      - name: Determine Workflow Status
        run: |
          if [[ "${{ needs.database-restoration.result }}" == "success" ]]; then
            echo "âœ… Database Restoration Completed Successfully"
          else
            echo "âŒ Database Restoration Failed"
            exit 1
          fi
