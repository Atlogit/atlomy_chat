name: Database Restoration Workflow

on:
  workflow_dispatch:
    inputs:
      deployment_mode:
        description: 'Deployment mode (development/production)'
        required: false
        default: 'production'
      force_restore:
        description: 'Force database restoration'
        type: boolean
        default: false
  workflow_call:
    inputs:
      deployment_mode:
        description: 'Deployment mode (development/production)'
        type: string
        required: false
        default: 'production'
      force_restore:
        description: 'Force database restoration'
        type: boolean
        default: false

permissions:
  id-token: write
  contents: read

jobs:
  pre-restore-checks:
    runs-on: ubuntu-latest
    outputs:
      should_restore: ${{ steps.check-conditions.outputs.should_restore }}
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Check Restoration Conditions
        id: check-conditions
        env:
          FORCE_RESTORE: ${{ inputs.force_restore || github.event.inputs.force_restore }}
          DEPLOYMENT_MODE: ${{ inputs.deployment_mode || github.event.inputs.deployment_mode || 'production' }}
        run: |
          echo "Deployment Mode: $DEPLOYMENT_MODE"
          echo "Force Restore: $FORCE_RESTORE"
          
          if [[ "$FORCE_RESTORE" == "true" ]]; then
            echo "should_restore=true" >> $GITHUB_OUTPUT
          else
            # Default logic - you can replace with more sophisticated checks
            echo "should_restore=true" >> $GITHUB_OUTPUT
          fi

  database-restoration:
    needs: pre-restore-checks
    if: needs.pre-restore-checks.outputs.should_restore == 'true'
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Configure AWS Credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: ${{ secrets.AWS_OIDC_ROLE_ARN }}
          aws-region: us-east-1

      - name: Prepare SSH Key
        env:
          EC2_SSH_KEY: ${{ secrets.EC2_SSH_PRIVATE_KEY }}
        run: |
          mkdir -p ~/.ssh
          echo "$EC2_SSH_KEY" > ~/.ssh/ec2_key
          chmod 600 ~/.ssh/ec2_key

      - name: Validate S3 Bucket and Find Latest Backup
        id: find-backup
        env:
          S3_BACKUP_BUCKET: ${{ secrets.S3_BACKUP_BUCKET }}
        run: |
          # Validate S3 bucket exists
          if ! aws s3 ls "s3://$S3_BACKUP_BUCKET" &> /dev/null; then
            echo "Error: S3 bucket $S3_BACKUP_BUCKET does not exist or is inaccessible"
            exit 1
          fi

          # Find latest backup
          latest_backup=$(aws s3 ls "s3://$S3_BACKUP_BUCKET/amta-db/" | grep '.tar.gz' | sort | tail -n 1 | awk '{print $4}')
          
          if [ -z "$latest_backup" ]; then
            echo "Error: No backup files found in S3 bucket"
            exit 1
          fi

          echo "Latest backup: $latest_backup"
          echo "backup_file=$latest_backup" >> $GITHUB_OUTPUT

      - name: Download and Transfer Backup
        env:
          S3_BACKUP_BUCKET: ${{ secrets.S3_BACKUP_BUCKET }}
          BACKUP_FILE: ${{ steps.find-backup.outputs.backup_file }}
          EC2_HOST: ${{ secrets.EC2_HOST }}
          EC2_USER: ${{ secrets.EC2_USER }}
        run: |
          # Download backup
          aws s3 cp "s3://$S3_BACKUP_BUCKET/amta-db/$BACKUP_FILE" ./latest_backup.tar.gz

          # Validate backup file
          if [ ! -f ./latest_backup.tar.gz ]; then
            echo "Error: Backup download failed"
            exit 1
          fi

          # SSH options
          SSH_OPTS="-o BatchMode=yes -o StrictHostKeyChecking=no"

          # Ensure remote backup directory exists
          ssh $SSH_OPTS -i ~/.ssh/ec2_key $EC2_USER@$EC2_HOST "mkdir -p /opt/atlomy/database_backups"

          # Transfer backup to EC2
          scp $SSH_OPTS -i ~/.ssh/ec2_key \
              ./latest_backup.tar.gz \
              $EC2_USER@$EC2_HOST:/opt/atlomy/database_backups/latest_backup.tar.gz

      - name: Prepare PostgreSQL Directory
        env:
          EC2_HOST: ${{ secrets.EC2_HOST }}
          EC2_USER: ${{ secrets.EC2_USER }}
        run: |
          SSH_OPTS="-o BatchMode=yes -o StrictHostKeyChecking=no"
          
          ssh $SSH_OPTS -i ~/.ssh/ec2_key $EC2_USER@$EC2_HOST << 'EOF'
            # Prepare PostgreSQL data directory
            sudo mkdir -p /var/lib/postgresql/data
            sudo chown -R 999:999 /var/lib/postgresql/data
            sudo chmod 700 /var/lib/postgresql/data

            # Extract backup
            sudo tar -xzpf /opt/atlomy/database_backups/latest_backup.tar.gz -C /var/lib/postgresql/data

            # Set correct permissions
            sudo chown -R 999:999 /var/lib/postgresql/data
          EOF

  notify-status:
    if: always()
    needs: [pre-restore-checks, database-restoration]
    runs-on: ubuntu-latest
    steps:
      - name: Determine Workflow Status
        run: |
          if [[ "${{ needs.database-restoration.result }}" == "success" ]]; then
            echo "✅ Database backup staging completed successfully"
          else
            echo "❌ Database backup staging failed"
            exit 1
          fi
