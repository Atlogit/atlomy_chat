name: Database Restoration Workflow

on:
  workflow_dispatch:
    inputs:
      deployment_mode:
        description: 'Deployment mode (development/production)'
        required: false
        default: 'production'
        type: choice
        options:
          - production
          - development
      force_restore:
        description: 'Force database restoration'
        type: boolean
        default: false
      s3_backup_bucket:
        description: 'S3 Bucket for Database Backups'
        required: true
        default: 'amta-app'
      s3_backup_prefix:
        description: 'S3 Prefix for Database Backups'
        type: string
        required: true
        default: 'amta-db'
  workflow_call:
    inputs:
      deployment_mode:
        description: 'Deployment mode (development/production)'
        type: string
        required: false
        default: 'production'
      force_restore:
        description: 'Force database restoration'
        type: boolean
        default: false
      s3_backup_bucket:
        description: 'S3 Bucket for Database Backups'
        type: string
        required: false
        default: 'amta-app'
      s3_backup_prefix:
        description: 'S3 Prefix for Database Backups'
        type: string
        required: false
        default: 'amta-db'

env:
  # Use environment variable for PostgreSQL data directory with default
  POSTGRES_DATA_DIR: ${POSTGRES_DATA_DIR:-/home/ec2-user/amta/data}
  # Use environment variable for database backups directory with default
  DATABASE_BACKUP_DIR: ${DATABASE_BACKUP_DIR:-/home/ec2-user/amta/database_backups}

permissions:
  id-token: write
  contents: read

jobs:
  database-restoration:
    runs-on: ubuntu-latest
    environment: ${{ inputs.deployment_mode }}

    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4

      - name: Configure AWS Credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: ${{ secrets.AWS_OIDC_ROLE_ARN }}
          aws-region: us-east-1

      - name: Retrieve Database Secrets
        id: get-database-secrets
        run: |
          if ! secrets=$(aws secretsmanager get-secret-value --secret-id amta-${{ inputs.deployment_mode }}-secrets --query SecretString --output text); then
            echo "Failed to retrieve secrets from AWS Secrets Manager"
            exit 1
          fi
          
          # Parse database connection details
          database_url=$(echo "$secrets" | jq -r '.DATABASE_URL')
          if [ -z "$database_url" ]; then
            echo "DATABASE_URL not found in secrets"
            exit 1
          fi
          
          # Extract database connection parameters
          postgres_host=$(echo "$database_url" | sed -E 's|postgresql\+asyncpg://[^:]+:[^@]+@([^:/]+).*|\1|')
          postgres_port=$(echo "$database_url" | sed -E 's|postgresql\+asyncpg://[^:]+:[^@]+@[^:/]+:?([0-9]+)?.*|\1|' || echo "5432")
          postgres_db=$(echo "$database_url" | sed -E 's|postgresql\+asyncpg://[^:]+:[^@]+@[^:/]+:?[0-9]*/([^?]+).*|\1|')
          postgres_user=$(echo "$database_url" | sed -E 's|postgresql\+asyncpg://([^:]+):.*|\1|')
          postgres_password=$(echo "$secrets" | jq -r '.POSTGRES_PASSWORD')
          
          # Validate extracted values
          for var in postgres_host postgres_db postgres_user postgres_password; do
            if [ -z "${!var}" ]; then
              echo "Failed to extract $var"
              exit 1
            fi
          done

          # Set outputs
          {
            echo "POSTGRES_HOST=$postgres_host"
            echo "POSTGRES_PORT=$postgres_port"
            echo "POSTGRES_DB=$postgres_db"
            echo "POSTGRES_USER=$postgres_user"
            echo "POSTGRES_PASSWORD=$postgres_password"
          } >> "$GITHUB_OUTPUT"

      - name: Prepare SSH Key
        env:
          EC2_SSH_KEY: ${{ secrets.EC2_SSH_PRIVATE_KEY }}
        run: |
          if [ -z "$EC2_SSH_KEY" ]; then
            echo "EC2 SSH key is not set"
            exit 1
          fi
          
          mkdir -p ~/.ssh
          echo "$EC2_SSH_KEY" > ~/.ssh/ec2_key
          chmod 600 ~/.ssh/ec2_key

      - name: Check Database Initialization Status
        id: check-database
        env:
          EC2_HOST: ${{ secrets.EC2_HOST }}
          EC2_USER: ${{ secrets.EC2_USER }}
        run: |
          ssh_opts="-o BatchMode=yes -o StrictHostKeyChecking=no -o ConnectTimeout=10"
          
          # Check if PostgreSQL data directory exists and contains PG_VERSION
          if ssh $ssh_opts -i ~/.ssh/ec2_key $EC2_USER@$EC2_HOST \
             "[ ! -f '$POSTGRES_DATA_DIR/PG_VERSION' ]"; then
            echo "Database not initialized. Restoration required."
            echo "restore_needed=true" >> $GITHUB_OUTPUT
          else
            echo "Database directory exists."
            echo "restore_needed=false" >> $GITHUB_OUTPUT
          fi

      - name: Discover Latest S3 Backup
        id: discover-backup
        env:
          S3_BACKUP_BUCKET: ${{ inputs.s3_backup_bucket }}
          S3_BACKUP_PREFIX: ${{ inputs.s3_backup_prefix }}
        run: |
          # List and sort backups by date, get the latest
          latest_backup=$(aws s3 ls "s3://$S3_BACKUP_BUCKET/$S3_BACKUP_PREFIX/" \
            | grep '\.tar\.gz$' \
            | sort -k1,2 \
            | tail -n 1 \
            | awk '{print $4}')
          
          if [ -z "$latest_backup" ]; then
            echo "‚ùå No backup files found in S3"
            exit 1
          fi

          # Get backup timestamp
          backup_timestamp=$(aws s3 ls "s3://$S3_BACKUP_BUCKET/$S3_BACKUP_PREFIX/$latest_backup" | awk '{print $1 " " $2}')
          
          echo "Latest backup: $latest_backup"
          echo "Backup timestamp: $backup_timestamp"
          echo "latest_backup=$latest_backup" >> $GITHUB_OUTPUT
          echo "backup_timestamp=$backup_timestamp" >> $GITHUB_OUTPUT

      - name: Compare Backup Timestamp
        id: compare-timestamp
        env:
          EC2_HOST: ${{ secrets.EC2_HOST }}
          EC2_USER: ${{ secrets.EC2_USER }}
          LATEST_BACKUP: ${{ steps.discover-backup.outputs.latest_backup }}
          BACKUP_TIMESTAMP: ${{ steps.discover-backup.outputs.backup_timestamp }}
          CHECK_DATABASE_RESTORE_NEEDED: ${{ steps.check-database.outputs.restore_needed }}
        run: |
          ssh_opts="-o BatchMode=yes -o StrictHostKeyChecking=no -o ConnectTimeout=10"
          
          # If database is already marked for restoration, skip timestamp comparison
          if [ "$CHECK_DATABASE_RESTORE_NEEDED" = "true" ]; then
            echo "Database already marked for restoration from previous check."
            echo "restore_needed=true" >> $GITHUB_OUTPUT
            exit 0
          fi
          
          # Perform timestamp comparison only if database exists
          ssh $ssh_opts -i ~/.ssh/ec2_key $EC2_USER@$EC2_HOST << REMOTE_SCRIPT
            set -e
            
            # Get local database timestamp
            local_timestamp=$(stat -c %y "$POSTGRES_DATA_DIR/PG_VERSION")
            
            # Convert timestamps to seconds since epoch
            backup_seconds=$(date -d "$BACKUP_TIMESTAMP" +%s)
            local_seconds=$(date -d "$local_timestamp" +%s)
            
            # Compare timestamps
            if [ "$backup_seconds" -gt "$local_seconds" ] || [ "${{ inputs.force_restore }}" = "true" ]; then
              echo "Backup is newer than local database or force restore requested."
              echo "restore_needed=true" >> $GITHUB_OUTPUT
            else
              echo "Local database is up to date."
              echo "restore_needed=false" >> $GITHUB_OUTPUT
            fi
          REMOTE_SCRIPT

      - name: Initialize PostgreSQL Data Directory
        id: init-postgres
        if: steps.compare-timestamp.outputs.restore_needed == 'true'
        env:
          POSTGRES_DB: ${{ steps.get-database-secrets.outputs.POSTGRES_DB }}
          POSTGRES_USER: ${{ steps.get-database-secrets.outputs.POSTGRES_USER }}
          POSTGRES_PASSWORD: ${{ steps.get-database-secrets.outputs.POSTGRES_PASSWORD }}
          EC2_HOST: ${{ secrets.EC2_HOST }}
          EC2_USER: ${{ secrets.EC2_USER }}
        run: |
          # Validate POSTGRES_DATA_DIR is set
          if [ -z "$POSTGRES_DATA_DIR" ]; then
            echo "‚ùå POSTGRES_DATA_DIR must be explicitly set"
            exit 1
          fi

          # Validate DATABASE_BACKUP_DIR is set
          if [ -z "$DATABASE_BACKUP_DIR" ]; then
            echo "‚ùå DATABASE_BACKUP_DIR must be explicitly set"
            exit 1
          fi

          ssh_opts="-o BatchMode=yes -o StrictHostKeyChecking=no -o ConnectTimeout=10"
          
          # Verify environment variables
          for var in POSTGRES_DB POSTGRES_USER POSTGRES_PASSWORD EC2_HOST EC2_USER; do
            if [ -z "${!var}" ]; then
              echo "Error: $var is not set"
              exit 1
            fi
          done

          # Execute remote initialization
          ssh $ssh_opts -i ~/.ssh/ec2_key $EC2_USER@$EC2_HOST << REMOTE_SCRIPT
            set -e
            
            echo "üîÑ Starting PostgreSQL initialization in $POSTGRES_DATA_DIR..."
            
            # Backup existing data if present and not empty
            if [ -d "$POSTGRES_DATA_DIR" ] && [ "$(ls -A "$POSTGRES_DATA_DIR")" ]; then
              timestamp=$(date +%Y%m%d_%H%M%S)
              sudo mkdir -p "$DATABASE_BACKUP_DIR"
              echo "üì¶ Backing up existing data..."
              sudo tar czf "${DATABASE_BACKUP_DIR}/pg_data_backup_${timestamp}.tar.gz" -C "$(dirname "$POSTGRES_DATA_DIR")" "$(basename "$POSTGRES_DATA_DIR")"
              sudo rm -rf "$POSTGRES_DATA_DIR"
            elif [ -d "$POSTGRES_DATA_DIR" ]; then
              echo "üìÅ Existing data directory is empty. Removing without backup."
              sudo rm -rf "$POSTGRES_DATA_DIR"
            fi
          
            # Setup postgres user and group
            if ! getent group postgres > /dev/null; then
              sudo groupadd postgres
            fi

            if ! id postgres > /dev/null 2>&1; then
              sudo useradd -g postgres -m postgres
            fi

            # Initialize data directory with explicit permissions
            echo "üìÅ Creating data directory: $POSTGRES_DATA_DIR"
            sudo mkdir -p "$POSTGRES_DATA_DIR"
            sudo chown -R postgres:postgres "$POSTGRES_DATA_DIR"
            sudo chmod 700 "$POSTGRES_DATA_DIR"

            # Verify Docker
            if ! command -v docker &> /dev/null || ! docker info &> /dev/null; then
              echo "‚ùå Docker is not available"
              exit 1
            fi

            echo "üê≥ Initializing PostgreSQL using Docker..."
            # Use su to run as postgres user to avoid root initialization
            sudo -u postgres bash -c '
              docker run --rm \
                -v "$POSTGRES_DATA_DIR:$POSTGRES_DATA_DIR" \
                -e POSTGRES_DB="$POSTGRES_DB" \
                -e POSTGRES_USER="$POSTGRES_USER" \
                -e POSTGRES_PASSWORD="$POSTGRES_PASSWORD" \
                postgres:14 \
                bash -c "
                  set -e
                  
                  # Verify directory permissions
                  if [ ! -w \"$POSTGRES_DATA_DIR\" ]; then
                    echo \"‚ùå Data directory is not writable\"
                    exit 1
                  fi
                  
                  echo \"üîß Running initdb...\"
                  initdb -D \"$POSTGRES_DATA_DIR\"
                  
                  echo \"üîí Setting permissions...\"
                  chmod 700 \"$POSTGRES_DATA_DIR\"
                "
            '
              
            # Verify initialization
            if [ ! -f "${POSTGRES_DATA_DIR}/PG_VERSION" ]; then
              echo "‚ùå PostgreSQL initialization failed"
              exit 1
            fi
            
            echo "‚úÖ PostgreSQL initialization completed successfully"
          REMOTE_SCRIPT

# (Rest of the workflow remains unchanged)
