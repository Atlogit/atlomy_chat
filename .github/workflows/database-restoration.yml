name: Database Restoration Workflow

on:
  workflow_dispatch:
    inputs:
      deployment_mode:
        description: 'Deployment mode (development/production)'
        required: false
        default: 'production'
        type: choice
        options:
          - production
          - development
      postgres_data_dir:
        description: 'PostgreSQL Data Directory'
        required: false
        default: '/home/ec2-user/amta/data'
      database_backup_dir:
        description: 'Database Backup Directory'
        required: false
        default: '/home/ec2-user/amta/database_backups'
      force_restore:
        description: 'Force database restoration'
        type: boolean
        default: false
      s3_backup_bucket:
        description: 'S3 Bucket for Database Backups'
        required: true
        default: 'amta-app'
      s3_backup_prefix:
        description: 'S3 Prefix for Database Backups'
        type: string
        required: true
        default: 'amta-db'
  workflow_call:
    inputs:
      deployment_mode:
        description: 'Deployment mode (development/production)'
        type: string
        required: false
        default: 'production'
      postgres_data_dir:
        description: 'PostgreSQL Data Directory'
        type: string
        required: false
        default: '/home/ec2-user/amta/data'
      database_backup_dir:
        description: 'Database Backup Directory'
        type: string
        required: false
        default: '/home/ec2-user/amta/database_backups'
      force_restore:
        description: 'Force database restoration'
        type: boolean
        default: false
      s3_backup_bucket:
        description: 'S3 Bucket for Database Backups'
        type: string
        required: false
        default: 'amta-app'
      s3_backup_prefix:
        description: 'S3 Prefix for Database Backups'
        type: string
        required: false
        default: 'amta-db'

env:
  # Use workflow input for PostgreSQL data directory
  POSTGRES_DATA_DIR: ${{ inputs.postgres_data_dir }}
  # Use workflow input for database backups directory
  DATABASE_BACKUP_DIR: ${{ inputs.database_backup_dir }}

permissions:
  id-token: write
  contents: read

jobs:
  database-restoration:
    runs-on: ubuntu-latest
    environment: ${{ inputs.deployment_mode }}

    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4

      - name: Configure AWS Credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: ${{ secrets.AWS_OIDC_ROLE_ARN }}
          aws-region: us-east-1

      - name: Validate Paths
        run: |
          echo "üìç PostgreSQL Data Directory: $POSTGRES_DATA_DIR"
          echo "üì¶ Database Backup Directory: $DATABASE_BACKUP_DIR"
          
          # Validate paths are not empty
          if [ -z "$POSTGRES_DATA_DIR" ]; then
            echo "‚ùå POSTGRES_DATA_DIR must be set"
            exit 1
          fi
          
          if [ -z "$DATABASE_BACKUP_DIR" ]; then
            echo "‚ùå DATABASE_BACKUP_DIR must be set"
            exit 1
          fi

      - name: Retrieve Database Secrets
        id: get-database-secrets
        run: |
          if ! secrets=$(aws secretsmanager get-secret-value --secret-id amta-${{ inputs.deployment_mode }}-secrets --query SecretString --output text); then
            echo "Failed to retrieve secrets from AWS Secrets Manager"
            exit 1
          fi
          
          # Parse database connection details
          database_url=$(echo "$secrets" | jq -r '.DATABASE_URL')
          if [ -z "$database_url" ]; then
            echo "DATABASE_URL not found in secrets"
            exit 1
          fi
          
          # Extract database connection parameters
          postgres_host=$(echo "$database_url" | sed -E 's|postgresql\+asyncpg://[^:]+:[^@]+@([^:/]+).*|\1|')
          postgres_port=$(echo "$database_url" | sed -E 's|postgresql\+asyncpg://[^:]+:[^@]+@[^:/]+:?([0-9]+)?.*|\1|' || echo "5432")
          postgres_db=$(echo "$database_url" | sed -E 's|postgresql\+asyncpg://[^:]+:[^@]+@[^:/]+:?[0-9]*/([^?]+).*|\1|')
          postgres_user=$(echo "$database_url" | sed -E 's|postgresql\+asyncpg://([^:]+):.*|\1|')
          postgres_password=$(echo "$secrets" | jq -r '.POSTGRES_PASSWORD')
          
          # Validate extracted values
          for var in postgres_host postgres_db postgres_user postgres_password; do
            if [ -z "${!var}" ]; then
              echo "Failed to extract $var"
              exit 1
            fi
          done

          # Set outputs
          {
            echo "POSTGRES_HOST=$postgres_host"
            echo "POSTGRES_PORT=$postgres_port"
            echo "POSTGRES_DB=$postgres_db"
            echo "POSTGRES_USER=$postgres_user"
            echo "POSTGRES_PASSWORD=$postgres_password"
          } >> "$GITHUB_OUTPUT"

      - name: Prepare SSH Key
        env:
          EC2_SSH_KEY: ${{ secrets.EC2_SSH_PRIVATE_KEY }}
        run: |
          if [ -z "$EC2_SSH_KEY" ]; then
            echo "EC2 SSH key is not set"
            exit 1
          fi
          
          mkdir -p ~/.ssh
          echo "$EC2_SSH_KEY" > ~/.ssh/ec2_key
          chmod 600 ~/.ssh/ec2_key

      - name: Check Database Initialization Status
        id: check-database
        env:
          EC2_HOST: ${{ secrets.EC2_HOST }}
          EC2_USER: ${{ secrets.EC2_USER }}
        run: |
          ssh_opts="-o BatchMode=yes -o StrictHostKeyChecking=no -o ConnectTimeout=10"
          
          # Check if PostgreSQL data directory exists and contains PG_VERSION
          if ssh $ssh_opts -i ~/.ssh/ec2_key "$EC2_USER@$EC2_HOST" \
             "[ ! -f '$POSTGRES_DATA_DIR/PG_VERSION' ]"; then
            echo "Database not initialized. Restoration required."
            echo "restore_needed=true" >> $GITHUB_OUTPUT
          else
            echo "Database directory exists."
            echo "restore_needed=false" >> $GITHUB_OUTPUT
          fi

      - name: Discover Latest S3 Backup
        id: discover-backup
        env:
          S3_BACKUP_BUCKET: ${{ inputs.s3_backup_bucket }}
          S3_BACKUP_PREFIX: ${{ inputs.s3_backup_prefix }}
        run: |
          # List and sort backups by date, get the latest
          latest_backup=$(aws s3 ls "s3://$S3_BACKUP_BUCKET/$S3_BACKUP_PREFIX/" \
            | grep '\.tar\.gz$' \
            | sort -k1,2 \
            | tail -n 1 \
            | awk '{print $4}')
          
          if [ -z "$latest_backup" ]; then
            echo "‚ùå No backup files found in S3"
            exit 1
          fi

          # Get backup timestamp
          backup_timestamp=$(aws s3 ls "s3://$S3_BACKUP_BUCKET/$S3_BACKUP_PREFIX/$latest_backup" | awk '{print $1 " " $2}')
          
          echo "Latest backup: $latest_backup"
          echo "Backup timestamp: $backup_timestamp"
          echo "latest_backup=$latest_backup" >> $GITHUB_OUTPUT
          echo "backup_timestamp=$backup_timestamp" >> $GITHUB_OUTPUT

      - name: Compare Backup Timestamp
        id: compare-timestamp
        env:
          EC2_HOST: ${{ secrets.EC2_HOST }}
          EC2_USER: ${{ secrets.EC2_USER }}
          LATEST_BACKUP: ${{ steps.discover-backup.outputs.latest_backup }}
          BACKUP_TIMESTAMP: ${{ steps.discover-backup.outputs.backup_timestamp }}
          CHECK_DATABASE_RESTORE_NEEDED: ${{ steps.check-database.outputs.restore_needed }}
        run: |
          ssh_opts="-o BatchMode=yes -o StrictHostKeyChecking=no -o ConnectTimeout=10"
          
          # If database is already marked for restoration, skip timestamp comparison
          if [ "$CHECK_DATABASE_RESTORE_NEEDED" = "true" ]; then
            echo "Database already marked for restoration from previous check."
            echo "restore_needed=true" >> $GITHUB_OUTPUT
            exit 0
          fi
          
          # Perform timestamp comparison only if database exists
          ssh $ssh_opts -i ~/.ssh/ec2_key "$EC2_USER@$EC2_HOST" << REMOTE_SCRIPT
            set -e
            
            # Get local database timestamp
            local_timestamp=$(stat -c %y "$POSTGRES_DATA_DIR/PG_VERSION")
            
            # Convert timestamps to seconds since epoch
            backup_seconds=$(date -d "$BACKUP_TIMESTAMP" +%s)
            local_seconds=$(date -d "$local_timestamp" +%s)
            
            # Compare timestamps
            if [ "$backup_seconds" -gt "$local_seconds" ] || [ "${{ inputs.force_restore }}" = "true" ]; then
              echo "Backup is newer than local database or force restore requested."
              echo "restore_needed=true" >> $GITHUB_OUTPUT
            else
              echo "Local database is up to date."
              echo "restore_needed=false" >> $GITHUB_OUTPUT
            fi
          REMOTE_SCRIPT

      - name: Initialize PostgreSQL Data Directory
        id: init-postgres
        if: steps.compare-timestamp.outputs.restore_needed == 'true'
        env:
          POSTGRES_DB: ${{ steps.get-database-secrets.outputs.POSTGRES_DB }}
          POSTGRES_USER: ${{ steps.get-database-secrets.outputs.POSTGRES_USER }}
          POSTGRES_PASSWORD: ${{ steps.get-database-secrets.outputs.POSTGRES_PASSWORD }}
          EC2_HOST: ${{ secrets.EC2_HOST }}
          EC2_USER: ${{ secrets.EC2_USER }}
        run: |
          # Explicitly set the full path to avoid variable expansion issues
          POSTGRES_DATA_DIR="/home/ec2-user/amta/data"
          DATABASE_BACKUP_DIR="/home/ec2-user/amta/database_backups"

          ssh_opts="-o BatchMode=yes -o StrictHostKeyChecking=no -o ConnectTimeout=10"
          
          # Verify environment variables
          for var in POSTGRES_DB POSTGRES_USER POSTGRES_PASSWORD EC2_HOST EC2_USER; do
            if [ -z "${!var}" ]; then
              echo "Error: $var is not set"
              exit 1
            fi
          done

          # Execute remote initialization
          ssh $ssh_opts -i ~/.ssh/ec2_key "$EC2_USER@$EC2_HOST" << REMOTE_SCRIPT
            set -e
            
            echo "üîÑ Starting PostgreSQL initialization in $POSTGRES_DATA_DIR..."
            
            # Ensure the exact directory exists with correct permissions
            sudo mkdir -p "$POSTGRES_DATA_DIR"
            sudo chown ec2-user:ec2-user "$POSTGRES_DATA_DIR"
            sudo chmod 755 "$POSTGRES_DATA_DIR"
            
            # Backup existing data if present and not empty
            if [ -d "$POSTGRES_DATA_DIR" ] && [ "$(ls -A "$POSTGRES_DATA_DIR")" ]; then
              timestamp=$(date +%Y%m%d_%H%M%S)
              sudo mkdir -p "$DATABASE_BACKUP_DIR"
              echo "üì¶ Backing up existing data..."
              sudo tar czf "${DATABASE_BACKUP_DIR}/pg_data_backup_${timestamp}.tar.gz" -C "$(dirname "$POSTGRES_DATA_DIR")" "$(basename "$POSTGRES_DATA_DIR")"
              sudo rm -rf "$POSTGRES_DATA_DIR"
            fi

            # Recreate directory with explicit permissions
            sudo mkdir -p "$POSTGRES_DATA_DIR"
            sudo chown ec2-user:ec2-user "$POSTGRES_DATA_DIR"
            sudo chmod 755 "$POSTGRES_DATA_DIR"

            # Verify Docker is available
            if ! command -v docker &> /dev/null; then
              echo "‚ùå Docker is not installed"
              exit 1
            fi

            # Run Docker initialization
            echo "üê≥ Initializing PostgreSQL using Docker..."
            docker run --rm \
              -v "$POSTGRES_DATA_DIR:$POSTGRES_DATA_DIR" \
              -e POSTGRES_DB="$POSTGRES_DB" \
              -e POSTGRES_USER="$POSTGRES_USER" \
              -e POSTGRES_PASSWORD="$POSTGRES_PASSWORD" \
              postgres:14 \
              bash -c "
                set -e
                
                # Verify directory permissions
                if [ ! -w \"$POSTGRES_DATA_DIR\" ]; then
                  echo \"‚ùå Data directory is not writable\"
                  exit 1
                fi
                
                echo \"üîß Running initdb...\"
                initdb -D \"$POSTGRES_DATA_DIR\"
                
                echo \"ÔøΩ Setting permissions...\"
                chmod 700 \"$POSTGRES_DATA_DIR\"
              "
              
            # Verify initialization
            if [ ! -f "${POSTGRES_DATA_DIR}/PG_VERSION" ]; then
              echo "‚ùå PostgreSQL initialization failed"
              exit 1
            fi
            
            echo "‚úÖ PostgreSQL initialization completed successfully"
          REMOTE_SCRIPT

      - name: Download Latest Backup
        id: download-backup
        if: steps.compare-timestamp.outputs.restore_needed == 'true'
        env:
          S3_BACKUP_BUCKET: ${{ inputs.s3_backup_bucket }}
          S3_BACKUP_PREFIX: ${{ inputs.s3_backup_prefix }}
          LATEST_BACKUP: ${{ steps.discover-backup.outputs.latest_backup }}
          EC2_HOST: ${{ secrets.EC2_HOST }}
          EC2_USER: ${{ secrets.EC2_USER }}
        run: |
          echo "üîç Downloading backup: $LATEST_BACKUP"
          
          ssh_opts="-o BatchMode=yes -o StrictHostKeyChecking=no -o ConnectTimeout=10"
          
          # Transfer and verify backup
          ssh $ssh_opts -i ~/.ssh/ec2_key "$EC2_USER@$EC2_HOST" << REMOTE_SCRIPT
            set -e
            
            # Ensure backup directory exists
            sudo mkdir -p "$DATABASE_BACKUP_DIR"
            sudo chown -R $USER:$USER "$DATABASE_BACKUP_DIR"
            
            echo "‚¨áÔ∏è Downloading backup from S3..."
            aws s3 cp "s3://$S3_BACKUP_BUCKET/$S3_BACKUP_PREFIX/$LATEST_BACKUP" \
              "$DATABASE_BACKUP_DIR/latest_backup.tar.gz"
            
            if [ ! -f "$DATABASE_BACKUP_DIR/latest_backup.tar.gz" ]; then
              echo "‚ùå Backup download failed"
              exit 1
            fi
            
            # Verify backup integrity and structure
            backup_contents=$(tar tzf $DATABASE_BACKUP_DIR/latest_backup.tar.gz)
            
            # Check if the backup contains a PostgreSQL data directory
            if ! echo "$backup_contents" | grep -q "PG_VERSION"; then
              echo "‚ùå Backup does not appear to be a valid PostgreSQL data directory"
              exit 1
            fi
            
            # Additional checks for PostgreSQL directory structure
            if ! echo "$backup_contents" | grep -q "base/"; then
              echo "‚ùå Backup is missing essential PostgreSQL data subdirectories"
              exit 1
            fi
            
            echo "‚úÖ Backup downloaded and verified successfully"
          REMOTE_SCRIPT

      - name: Restore Database
        id: restore-database
        if: steps.download-backup.outcome == 'success'
        env:
          POSTGRES_HOST: ${{ steps.get-database-secrets.outputs.POSTGRES_HOST }}
          POSTGRES_PORT: ${{ steps.get-database-secrets.outputs.POSTGRES_PORT }}
          POSTGRES_DB: ${{ steps.get-database-secrets.outputs.POSTGRES_DB }}
          POSTGRES_USER: ${{ steps.get-database-secrets.outputs.POSTGRES_USER }}
          POSTGRES_PASSWORD: ${{ steps.get-database-secrets.outputs.POSTGRES_PASSWORD }}
          EC2_HOST: ${{ secrets.EC2_HOST }}
          EC2_USER: ${{ secrets.EC2_USER }}
        run: |
          ssh_opts="-o BatchMode=yes -o StrictHostKeyChecking=no -o ConnectTimeout=10"
          
          ssh $ssh_opts -i ~/.ssh/ec2_key "$EC2_USER@$EC2_HOST" << 'REMOTE_SCRIPT'
            set -e
            
            echo "ÔøΩ Starting database restoration process..."
            
            # Ensure PostgreSQL is stopped before restoration
            sudo systemctl stop postgresql || true
            
            # Remove existing data directory
            if [ -d "$POSTGRES_DATA_DIR" ]; then
              sudo rm -rf "$POSTGRES_DATA_DIR"
            fi
            
            # Create clean data directory
            sudo mkdir -p "$POSTGRES_DATA_DIR"
            sudo chown -R postgres:postgres "$POSTGRES_DATA_DIR"
            sudo chmod 700 "$POSTGRES_DATA_DIR"
            
            # Create temporary directory for extraction
            TEMP_DIR=$(mktemp -d)
            trap 'rm -rf "$TEMP_DIR"' EXIT
            
            # Extract backup
            echo "ÔøΩ Extracting backup..."
            sudo tar xzf "$DATABASE_BACKUP_DIR/latest_backup.tar.gz" -C "$TEMP_DIR"
            
            # Determine backup type
            DUMP_FILE=$(find "$TEMP_DIR" -name "*.dump" -type f)
            PG_VERSION_FILE=$(find "$TEMP_DIR" -name "PG_VERSION" -type f)
            
            if [ -n "$PG_VERSION_FILE" ]; then
              echo "üóÇÔ∏è Full PostgreSQL data directory backup detected"
              
              # Copy entire data directory
              sudo cp -R "$TEMP_DIR"/* "$POSTGRES_DATA_DIR"              
              # Ensure correct ownership and permissions
              sudo chown -R postgres:postgres "$POSTGRES_DATA_DIR"
              sudo chmod 700 "$POSTGRES_DATA_DIR"
              
              # Verify PostgreSQL data directory
              if [ ! -f "$POSTGRES_DATA_DIR/PG_VERSION" ]; then
                echo "‚ùå PostgreSQL data directory restoration failed"
                exit 1
              fi
            
            elif [ -n "$DUMP_FILE" ]; then
              echo "üìÑ Database dump file detected"
              
              # Ensure PostgreSQL data directory is initialized
              sudo -u postgres initdb -D "$POSTGRES_DATA_DIR"
              
              # Drop existing connections
              export PGPASSWORD="$POSTGRES_PASSWORD"
              psql -h "$POSTGRES_HOST" -U "$POSTGRES_USER" -c "SELECT pg_terminate_backend(pid) FROM pg_stat_activity WHERE datname = '$POSTGRES_DB' AND pid <> pg_backend_pid();"
              
              # Restore the database from dump
              pg_restore --clean --if-exists --no-owner --no-privileges -h "$POSTGRES_HOST" -U "$POSTGRES_USER" -d "$POSTGRES_DB" "$DUMP_FILE"
              
              # Verify restoration
              if ! psql -h "$POSTGRES_HOST" -U "$POSTGRES_USER" -d "$POSTGRES_DB" -c "SELECT COUNT(*) FROM information_schema.tables WHERE table_schema = 'public';" | grep -q '[1-9]'; then
                echo "‚ùå Database restoration from dump failed or resulted in empty database"
                exit 1
              fi
            
            else
              echo "‚ùå No valid backup found: neither PostgreSQL data directory nor dump file detected"
              exit 1
            fi
            
            # Restart PostgreSQL to apply changes
            sudo systemctl start postgresql
            
            # Wait for PostgreSQL to start
            sleep 10
            
            # Verify database connectivity
            export PGPASSWORD="$POSTGRES_PASSWORD"
            if ! psql -h "$POSTGRES_HOST" -U "$POSTGRES_USER" -d "$POSTGRES_DB" -c "SELECT 1" &> /dev/null; then
              echo "‚ùå Unable to connect to restored database"
              exit 1
            fi
            
            echo "‚úÖ Database restored successfully"
            echo "restore_status=success" >> $GITHUB_OUTPUT
          REMOTE_SCRIPT

  notify-status:
    if: always()
    needs: [database-restoration]
    runs-on: ubuntu-latest
    steps:
      - name: Determine Workflow Status
        run: |
          if [[ "${{ needs.database-restoration.result }}" == 'success' ]]; then
            echo "‚úÖ Database Restoration Completed Successfully"
          else
            echo "‚ùå Database Restoration Failed"
            exit 1
          fi
