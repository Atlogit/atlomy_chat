name: Database Restoration Workflow

on:
  workflow_dispatch:
    inputs:
      deployment_mode:
        description: 'Deployment mode (development/production)'
        required: false
        default: 'production'
      force_restore:
        description: 'Force database restoration'
        type: boolean
        default: false
      s3_backup_bucket:
        description: 'S3 Bucket for Database Backups'
        required: true
        default: 'amta-app'
      s3_backup_prefix:
        description: 'S3 Prefix for Database Backups'
        required: true
        default: 'amta-db'
  workflow_call:
    inputs:
      deployment_mode:
        description: 'Deployment mode (development/production)'
        type: string
        required: false
        default: 'production'
      force_restore:
        description: 'Force database restoration'
        type: boolean
        default: false
      s3_backup_bucket:
        description: 'S3 Bucket for Database Backups'
        type: string
        required: false
        default: 'amta-app'
      s3_backup_prefix:
        description: 'S3 Prefix for Database Backups'
        type: string
        required: false
        default: 'amta-db'

permissions:
  id-token: write
  contents: read

jobs:
  database-restoration:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4

      - name: Configure AWS Credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: ${{ secrets.AWS_OIDC_ROLE_ARN }}
          aws-region: us-east-1

      - name: Retrieve Database Secrets
        id: get-database-secrets
        run: |
          secrets=$(aws secretsmanager get-secret-value --secret-id amta-production-secrets --query SecretString --output text)
          
          database_url=$(echo "$secrets" | jq -r '.DATABASE_URL')
          postgres_host=$(echo "$database_url" | sed -E 's|postgresql\+asyncpg://[^:]+:[^@]+@([^:/]+).*|\1|')
          postgres_port=$(echo "$database_url" | sed -E 's|postgresql\+asyncpg://[^:]+:[^@]+@[^:/]+:?([0-9]+)?.*|\1|' || echo "5432")
          postgres_db=$(echo "$database_url" | sed -E 's|postgresql\+asyncpg://[^:]+:[^@]+@[^:/]+:?[0-9]*/([^?]+).*|\1|')
          postgres_user=$(echo "$database_url" | sed -E 's|postgresql\+asyncpg://([^:]+):.*|\1|')
          postgres_password=$(echo "$secrets" | jq -r '.POSTGRES_PASSWORD')

          echo "POSTGRES_HOST=$postgres_host" >> $GITHUB_OUTPUT
          echo "POSTGRES_PORT=$postgres_port" >> $GITHUB_OUTPUT
          echo "POSTGRES_DB=$postgres_db" >> $GITHUB_OUTPUT
          echo "POSTGRES_USER=$postgres_user" >> $GITHUB_OUTPUT
          echo "POSTGRES_PASSWORD=$postgres_password" >> $GITHUB_OUTPUT

          echo "üîç Database Connection Details:"
          echo "  Host: $postgres_host"
          echo "  Port: $postgres_port"
          echo "  Database: $postgres_db"
          echo "  User: $postgres_user"

      - name: Prepare SSH Key
        env:
          EC2_SSH_KEY: ${{ secrets.EC2_SSH_PRIVATE_KEY }}
        run: |
          mkdir -p ~/.ssh
          echo "$EC2_SSH_KEY" > ~/.ssh/ec2_key
          chmod 600 ~/.ssh/ec2_key

      - name: Check PostgreSQL Data Directory
        id: check-postgres-data
        env:
          EC2_HOST: ${{ secrets.EC2_HOST }}
          EC2_USER: ${{ secrets.EC2_USER }}
        run: |
          SSH_OPTS="-o BatchMode=yes -o StrictHostKeyChecking=no"
          
          # Connect to the remote host and inspect the PostgreSQL data directory
          ssh $SSH_OPTS -i ~/.ssh/ec2_key $EC2_USER@$EC2_HOST << 'REMOTE_SCRIPT'
            # Check if data directory exists
            if [ -d "/var/lib/postgresql/data" ]; then   
              # Check directory permissions
              if [ -r "/var/lib/postgresql/data" ] && [ -x "/var/lib/postgresql/data" ]; then
                # Directory is accessible, count files

                file_count=$(find /var/lib/postgresql/data -type f | wc -l)
                if [ "\$file_count" -gt 0 ]; then
                  echo "‚úÖ PostgreSQL data directory exists and contains files"
                  echo "postgres_data_status=populated" >> $GITHUB_OUTPUT
                else
                  echo "‚ö†Ô∏è PostgreSQL data directory is empty"
                  echo "postgres_data_status=empty" >> $GITHUB_OUTPUT
                fi
              else
                # Directory is inaccessible
                echo "‚ùå Access denied to /var/lib/postgresql/data"
                echo "postgres_data_status=access_denied" >> $GITHUB_OUTPUT
                exit 0
              fi
            else
              echo "‚ùå PostgreSQL data directory does not exist"
              mkdir -p /var/lib/postgresql/data
              echo "‚ö†Ô∏è PostgreSQL data directory created"
              echo "postgres_data_status=empty" >> $GITHUB_OUTPUT
            fi
          REMOTE_SCRIPT
        continue-on-error: false

      - name: Skip Restoration if Data Directory is Inaccessible
        id: skip-restoration-process
        if: steps.check-postgres-data.outputs.postgres_data_status == 'access_denied'
        run: |
          echo "‚ö†Ô∏è Data directory is already in use or inaccessible. Skipping restoration."
          exit 0

      - name: Check Backup File Availability
        id: check-backup-file
        if: steps.check-postgres-data.outputs.postgres_data_status == 'empty'
        env:
          EC2_HOST: ${{ secrets.EC2_HOST }}
          EC2_USER: ${{ secrets.EC2_USER }}
        run: |
          SSH_OPTS="-o BatchMode=yes -o StrictHostKeyChecking=no"
          # Check backup file in /opt/atlomy/database_backups
          ssh $SSH_OPTS -i ~/.ssh/ec2_key $EC2_USER@$EC2_HOST << 'REMOTE_SCRIPT'
            # Ensure backup directory exists
            if [ -d "/opt/atlomy/database_backups" ]; then            
              # Check for backup file
              if [ -f "/opt/atlomy/database_backups/latest_backup.tar.gz" ]; then
                echo "‚úÖ Backup file exists in /opt/atlomy/database_backups"
                echo "backup_file_status=exists" >> $GITHUB_OUTPUT
            else
              echo "‚ùå No backup file in /opt/atlomy/database_backups"
              echo "backup_file_status=missing" >> $GITHUB_OUTPUT
            fi
          else
            echo "Backup folder is missing"
            mkdir -p /opt/atlomy/database_backups
            echo "Creatd backup database_backups folder"
            echo "backup_file_status=missing" >> $GITHUB_OUTPUT
          fi
          REMOTE_SCRIPT
        continue-on-error: false

      - name: Download Backup from S3
        id: download-backup
        if: steps.check-backup-file.outputs.backup_file_status == 'missing'
        env:
          S3_BACKUP_BUCKET: ${{ inputs.s3_backup_bucket || 'amta-app' }}
          S3_BACKUP_PREFIX: ${{ inputs.s3_backup_prefix || 'amta-db' }}
          EC2_HOST: ${{ secrets.EC2_HOST }}
          EC2_USER: ${{ secrets.EC2_USER }}
        run: |
          echo "üìã Discovering Latest Backup"
          latest_backup=$(aws s3 ls "s3://$S3_BACKUP_BUCKET/$S3_BACKUP_PREFIX/" | grep '.tar.gz' | sort | tail -n 1 | awk '{print $4}')
          
          if [ -z "$latest_backup" ]; then
            echo "‚ùå Error: No backup files found in S3 bucket"
            exit 1
          fi

          echo "üè∑Ô∏è Latest Backup: $latest_backup"
          SSH_OPTS="-o BatchMode=yes -o StrictHostKeyChecking=no"
          echo "backup_file_status=exists" >> $GITHUB_OUTPUT

          # Transfer backup to EC2
          ssh $SSH_OPTS -i ~/.ssh/ec2_key $EC2_USER@$EC2_HOST << REMOTE_SCRIPT
          aws s3 cp "s3://$S3_BACKUP_BUCKET/$S3_BACKUP_PREFIX/$latest_backup" /opt/atlomy/database_backups/latest_backup.tar.gz  
          # Verify download
          if [ -f "/opt/atlomy/database_backups/latest_backup.tar.gz" ]; then
            echo "‚úÖ Backup downloaded successfully"
            echo "download_status=success" >> $GITHUB_OUTPUT
            echo "backup_file_status=exists" >> $GITHUB_OUTPUT
          else
            echo "‚ùå Backup download failed"
            echo "download_status=failed" >> $GITHUB_OUTPUT
            exit 1
          fi
          REMOTE_SCRIPT

      - name: Restore PostgreSQL Database
        env:
          POSTGRES_HOST: ${{ steps.get-database-secrets.outputs.POSTGRES_HOST }}
          POSTGRES_PORT: ${{ steps.get-database-secrets.outputs.POSTGRES_PORT }}
          POSTGRES_DB: ${{ steps.get-database-secrets.outputs.POSTGRES_DB }}
          POSTGRES_USER: ${{ steps.get-database-secrets.outputs.POSTGRES_USER }}
          POSTGRES_PASSWORD: ${{ steps.get-database-secrets.outputs.POSTGRES_PASSWORD }}
          EC2_HOST: ${{ secrets.EC2_HOST }}
          EC2_USER: ${{ secrets.EC2_USER }}
          S3_BACKUP_BUCKET: ${{ inputs.s3_backup_bucket || 'amta-app' }}
          S3_BACKUP_PREFIX: ${{ inputs.s3_backup_prefix || 'amta-db' }}
        run: |
          SSH_OPTS="-o BatchMode=yes -o StrictHostKeyChecking=no"
          
          ssh $SSH_OPTS -i ~/.ssh/ec2_key $EC2_USER@$EC2_HOST << EOF
            export PGPASSWORD=$POSTGRES_PASSWORD
            
            # Check the data directory state
            if steps.check-postgres-data.outputs.postgres_data_status == 'empty'; then
              if steps.check-backup-file.outputs.backup_file_status == 'exists'; then
                # Extract the backup file to the data directory
                echo "Extracting backup file to /var/lib/postgresql/data..."
                  tar -xzf /opt/atlomy/database_backups/latest_backup.tar.gz -C /var/lib/postgresql/data
                  chown -R postgres:postgres /var/lib/postgresql/data
                  echo "‚úÖ Backup extracted successfully"
                  postgres_data_status=populated
              else
                echo "‚ö†Ô∏è No backup file found. Skipping extraction and restoration."
                exit 1
              fi
            elif steps.check-postgres-data.outputs.postgres_data_status == 'populated'; then
              fi
            else
              echo "‚ö†Ô∏è Unexpected data directory state. Exiting."
              echo "postgres_data_status=error" >> $GITHUB_ENV
              exit 1
            fi              
            
            #Proceed to DB restoration
            echo "üîÑ Restoring database..."
            # List the extracted files to find the actual backup file
            extracted_file=$(ls /var/lib/postgresql/data | grep -E "\.dump|\.sql")
            # Check if a .dump or .sql file was extracted
            if [[ -z "$extracted_file" ]]; then
              echo "‚ö†Ô∏è No valid backup file found in the extracted archive."
              exit 1
            fi
            
            # Restore the database using pg_restore (if it's a .dump file)
            if [[ "$extracted_file" =~ \.dump$ ]]; then
              echo "Restoring database from custom format dump..."
              # Drop existing database
              psql -h "$POSTGRES_HOST" -U "$POSTGRES_USER" -c "DROP DATABASE IF EXISTS \"$POSTGRES_DB\";"
            
              # Create new database
              psql -h "$POSTGRES_HOST" -U "$POSTGRES_USER" -c "CREATE DATABASE \"$POSTGRES_DB\";"
              
              # Restore backup
              pg_restore -h "$POSTGRES_HOST" -U "$POSTGRES_USER" -d "$POSTGRES_DB" "/var/lib/postgresql/data/$extracted_file"

            # If it's a plain SQL file, use psql instead
            elif [[ "$extracted_file" =~ \.sql$ ]]; then
              echo "Restoring database from plain SQL dump..."
              # Drop existing database
              psql -h "$POSTGRES_HOST" -U "$POSTGRES_USER" -c "DROP DATABASE IF EXISTS \"$POSTGRES_DB\";"
            
              # Create new database
              psql -h "$POSTGRES_HOST" -U "$POSTGRES_USER" -c "CREATE DATABASE \"$POSTGRES_DB\";"
            
              # Restore backup
              psql -h "$POSTGRES_HOST" -U "$POSTGRES_USER" -d "$POSTGRES_DB" -f "/var/lib/postgresql/data/$extracted_file"
            fi
            
            else
              echo "‚ö†Ô∏è No backup file found. Skipping restoration."
            fi
            exit 1
            
            # Verify restoration
          table_count=$(psql -h "$POSTGRES_HOST" -U "$POSTGRES_USER" -d "$POSTGRES_DB" -t -c "SELECT COUNT(*) FROM information_schema.tables WHERE table_schema = 'public';")
            
          if [ "\$table_count" -eq 0 ]; then
            echo "‚ùå Database restoration failed: No tables found"
            exit 1
          fi
            
          echo "‚úÖ Database restored successfully. Tables found: \$table_count"
          EOF

  notify-status:
    if: always()
    needs: [database-restoration]
    runs-on: ubuntu-latest
    steps:
      - name: Determine Workflow Status
        run: |
          if [[ "${{ needs.database-restoration.result }}" == "success" ]]; then
            echo "‚úÖ Database Restoration Completed Successfully"
          else
            echo "‚ùå Database Restoration Failed"
            exit 1
          fi
