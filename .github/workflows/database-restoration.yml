name: Database Restoration Workflow

on:
  workflow_dispatch:
    inputs:
      deployment_mode:
        description: 'Deployment mode (development/production)'
        required: false
        default: 'production'
      force_restore:
        description: 'Force database restoration'
        type: boolean
        default: false
      s3_backup_bucket:
        description: 'S3 Bucket for Database Backups'
        required: true
        default: 'amta-app'
      s3_backup_prefix:
        description: 'S3 Prefix for Database Backups'
        type: string
        required: true
        default: 'amta-db'
  workflow_call:
    inputs:
      deployment_mode:
        description: 'Deployment mode (development/production)'
        type: string
        required: false
        default: 'production'
      force_restore:
        description: 'Force database restoration'
        type: boolean
        default: false
      s3_backup_bucket:
        description: 'S3 Bucket for Database Backups'
        type: string
        required: false
        default: 'amta-app'
      s3_backup_prefix:
        description: 'S3 Prefix for Database Backups'
        type: string
        required: false
        default: 'amta-db'

permissions:
  id-token: write
  contents: read

jobs:
  database-restoration:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4

      - name: Configure AWS Credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: ${{ secrets.AWS_OIDC_ROLE_ARN }}
          aws-region: us-east-1

      - name: Retrieve Database Secrets
        id: get-database-secrets
        run: |
          secrets=$(aws secretsmanager get-secret-value --secret-id amta-production-secrets --query SecretString --output text)
          
          database_url=$(echo "$secrets" | jq -r '.DATABASE_URL')
          postgres_host=$(echo "$database_url" | sed -E 's|postgresql\+asyncpg://[^:]+:[^@]+@([^:/]+).*|\1|')
          postgres_port=$(echo "$database_url" | sed -E 's|postgresql\+asyncpg://[^:]+:[^@]+@[^:/]+:?([0-9]+)?.*|\1|' || echo "5432")
          postgres_db=$(echo "$database_url" | sed -E 's|postgresql\+asyncpg://[^:]+:[^@]+@[^:/]+:?[0-9]*/([^?]+).*|\1|')
          postgres_user=$(echo "$database_url" | sed -E 's|postgresql\+asyncpg://([^:]+):.*|\1|')
          postgres_password=$(echo "$secrets" | jq -r '.POSTGRES_PASSWORD')

          echo "POSTGRES_HOST=$postgres_host" >> $GITHUB_OUTPUT
          echo "POSTGRES_PORT=$postgres_port" >> $GITHUB_OUTPUT
          echo "POSTGRES_DB=$postgres_db" >> $GITHUB_OUTPUT
          echo "POSTGRES_USER=$postgres_user" >> $GITHUB_OUTPUT
          echo "POSTGRES_PASSWORD=$postgres_password" >> $GITHUB_OUTPUT

      - name: Prepare SSH Key
        env:
          EC2_SSH_KEY: ${{ secrets.EC2_SSH_PRIVATE_KEY }}
        run: |
          mkdir -p ~/.ssh
          echo "$EC2_SSH_KEY" > ~/.ssh/ec2_key
          chmod 600 ~/.ssh/ec2_key

      - name: Initialize PostgreSQL Data Directory
        env:
          POSTGRES_DB: ${{ steps.get-database-secrets.outputs.POSTGRES_DB }}
          POSTGRES_USER: ${{ steps.get-database-secrets.outputs.POSTGRES_USER }}
          POSTGRES_PASSWORD: ${{ steps.get-database-secrets.outputs.POSTGRES_PASSWORD }}
          EC2_HOST: ${{ secrets.EC2_HOST }}
          EC2_USER: ${{ secrets.EC2_USER }}
        run: |
          SSH_OPTS="-o BatchMode=yes -o StrictHostKeyChecking=no"
          
          ssh $SSH_OPTS -i ~/.ssh/ec2_key $EC2_USER@$EC2_HOST << EOF
            # Ensure backup directory exists
            mkdir -p /opt/atlomy/database_backups

            # Remove existing data directory if it's problematic
            if [ -d "/var/lib/postgresql/data" ]; then
              sudo rm -rf /var/lib/postgresql/data
            fi

            # Create data directory with correct permissions
            sudo mkdir -p /var/lib/postgresql/data
            sudo chown -R 999:999 /var/lib/postgresql/data
            sudo chmod 700 /var/lib/postgresql/data

            # Initialize data directory using Docker
            docker run --rm \
              -v /var/lib/postgresql/data:/var/lib/postgresql/data \
              -e POSTGRES_DB=$POSTGRES_DB \
              -e POSTGRES_USER=$POSTGRES_USER \
              -e POSTGRES_PASSWORD=$POSTGRES_PASSWORD \
              postgres:latest \
              bash -c "
                # Initialize PostgreSQL data directory
                initdb -D /var/lib/postgresql/data
                
                # Ensure correct permissions
                chown -R postgres:postgres /var/lib/postgresql/data
              "

            echo "‚úÖ PostgreSQL data directory initialized successfully"
          EOF

      # Rest of the existing workflow remains the same (Check PostgreSQL Data Directory, etc.)
      - name: Check PostgreSQL Data Directory
        id: check-postgres-data
        env:
          EC2_HOST: ${{ secrets.EC2_HOST }}
          EC2_USER: ${{ secrets.EC2_USER }}
        run: |
          SSH_OPTS="-o BatchMode=yes -o StrictHostKeyChecking=no"
          
          # Connect to the remote host and inspect the PostgreSQL data directory
          ssh $SSH_OPTS -i ~/.ssh/ec2_key $EC2_USER@$EC2_HOST << 'REMOTE_SCRIPT'
            # Check if data directory exists
            if [ -d "/var/lib/postgresql/data" ]; then   
              # Check directory permissions
              if [ -r "/var/lib/postgresql/data" ] && [ -x "/var/lib/postgresql/data" ]; then
                # Directory is accessible, count files

                file_count=$(find /var/lib/postgresql/data -type f | wc -l)
                if [ "\$file_count" -gt 0 ]; then
                  echo "‚úÖ PostgreSQL data directory exists and contains files"
                  echo "postgres_data_status=populated" >> $GITHUB_OUTPUT
                else
                  echo "‚ö†Ô∏è PostgreSQL data directory is empty"
                  echo "postgres_data_status=empty" >> $GITHUB_OUTPUT
                fi
              else
                # Directory is inaccessible
                echo "‚ùå Access denied to /var/lib/postgresql/data"
                echo "postgres_data_status=access_denied" >> $GITHUB_OUTPUT
                exit 0
              fi
            else
              echo "‚ùå PostgreSQL data directory does not exist"
              mkdir -p /var/lib/postgresql/data
              echo "‚ö†Ô∏è PostgreSQL data directory created"
              echo "postgres_data_status=empty" >> $GITHUB_OUTPUT
            fi
          REMOTE_SCRIPT
        continue-on-error: false

      - name: Skip Restoration if Data Directory is Inaccessible
        id: skip-restoration-process
        if: steps.check-postgres-data.outputs.postgres_data_status == 'access_denied'
        run: |
          echo "‚ö†Ô∏è Data directory is already in use or inaccessible. Skipping restoration."
          exit 0

      - name: Check Backup File Availability
        id: check-backup-file
        if: steps.check-postgres-data.outputs.postgres_data_status == 'empty'
        env:
          EC2_HOST: ${{ secrets.EC2_HOST }}
          EC2_USER: ${{ secrets.EC2_USER }}
        run: |
          SSH_OPTS="-o BatchMode=yes -o StrictHostKeyChecking=no"
          # Check backup file in /opt/atlomy/database_backups
          ssh $SSH_OPTS -i ~/.ssh/ec2_key $EC2_USER@$EC2_HOST << 'REMOTE_SCRIPT'
            # Ensure backup directory exists
            if [ -d "/opt/atlomy/database_backups" ]; then            
              # Check for backup file
              if [ -f "/opt/atlomy/database_backups/latest_backup.tar.gz" ]; then
                echo "‚úÖ Backup file exists in /opt/atlomy/database_backups"
                echo "backup_file_status=exists" >> $GITHUB_OUTPUT
              else
                echo "‚ùå No backup file in /opt/atlomy/database_backups"
                echo "backup_file_status=missing" >> $GITHUB_OUTPUT
              fi
            else
              echo "Backup folder is missing"
              mkdir -p /opt/atlomy/database_backups
              echo "Created backup database_backups folder"
              echo "backup_file_status=missing" >> $GITHUB_OUTPUT
            fi
          REMOTE_SCRIPT
        continue-on-error: false

      - name: Download Backup from S3
        id: download-backup
        if: steps.check-backup-file.outputs.backup_file_status == 'missing'
        env:
          S3_BACKUP_BUCKET: ${{ inputs.s3_backup_bucket || 'amta-app' }}
          S3_BACKUP_PREFIX: ${{ inputs.s3_backup_prefix || 'amta-db' }}
          EC2_HOST: ${{ secrets.EC2_HOST }}
          EC2_USER: ${{ secrets.EC2_USER }}
        run: |
          echo "üìã Discovering Latest Backup"
          latest_backup=$(aws s3 ls "s3://$S3_BACKUP_BUCKET/$S3_BACKUP_PREFIX/" | grep '.tar.gz' | sort | tail -n 1 | awk '{print $4}')
          
          if [ -z "$latest_backup" ]; then
            echo "‚ùå Error: No backup files found in S3 bucket"
            exit 1
          fi

          echo "üè∑Ô∏è Latest Backup: $latest_backup"
          SSH_OPTS="-o BatchMode=yes -o StrictHostKeyChecking=no"
          echo "backup_file_status=exists" >> $GITHUB_OUTPUT

          # Transfer backup to EC2
          ssh $SSH_OPTS -i ~/.ssh/ec2_key $EC2_USER@$EC2_HOST << REMOTE_SCRIPT
          aws s3 cp "s3://$S3_BACKUP_BUCKET/$S3_BACKUP_PREFIX/$latest_backup" /opt/atlomy/database_backups/latest_backup.tar.gz  
          # Verify download
          if [ -f "/opt/atlomy/database_backups/latest_backup.tar.gz" ]; then
            echo "‚úÖ Backup downloaded successfully"
            echo "download_status=success" >> $GITHUB_OUTPUT
            echo "backup_file_status=exists" >> $GITHUB_OUTPUT
          else
            echo "‚ùå Backup download failed"
            echo "download_status=failed" >> $GITHUB_OUTPUT
            exit 1
          fi
          REMOTE_SCRIPT

      - name: Restore PostgreSQL Database
        id: restore-postgres-data
        env:
          POSTGRES_HOST: ${{ steps.get-database-secrets.outputs.POSTGRES_HOST }}
          POSTGRES_DB: ${{ steps.get-database-secrets.outputs.POSTGRES_DB }}
          POSTGRES_USER: ${{ steps.get-database-secrets.outputs.POSTGRES_USER }}
          POSTGRES_PASSWORD: ${{ steps.get-database-secrets.outputs.POSTGRES_PASSWORD }}
          EC2_HOST: ${{ secrets.EC2_HOST }}
          EC2_USER: ${{ secrets.EC2_USER }}
        run: |
          SSH_OPTS="-o BatchMode=yes -o StrictHostKeyChecking=no"
          
          ssh $SSH_OPTS -i ~/.ssh/ec2_key $EC2_USER@$EC2_HOST << EOF
            export PGPASSWORD=$POSTGRES_PASSWORD
            # Check if PostgreSQL data directory is initialized
              if sudo -u postgres test -f "/var/lib/postgresql/data/PG_VERSION"; then
              echo "‚úÖ PostgreSQL data directory is initialized."
              
              # Verify if the database is populated
              table_count=\$(sudo -u postgres psql -h "$POSTGRES_HOST" -U "$POSTGRES_USER" -d "$POSTGRES_DB" -t -c \
                "SELECT COUNT(*) FROM information_schema.tables WHERE table_schema = 'public';")
              
              if [ "\$table_count" -gt 0 ]; then
                echo "‚úÖ Database is populated. Tables found: \$table_count"
                echo "postgres_data_status=populated" >> $GITHUB_OUTPUT
              else
                echo "‚ö†Ô∏è Database directory exists but no tables are found."
                echo "postgres_data_status=empty" >> $GITHUB_OUTPUT
              fi
            else
              echo "‚ö†Ô∏è PostgreSQL data directory is not initialized or inaccessible."
              echo "postgres_data_status=not_initialized" >> $GITHUB_OUTPUT
            fi

            # If database is empty, restore from backup
            if [ "\${{ steps.check-postgres-data.outputs.postgres_data_status }}" = "empty" ]; then
              if [ -f "/opt/atlomy/database_backups/latest_backup.tar.gz" ]; then
                echo "Extracting backup file to /var/lib/postgresql/data..."
                tar -xzf /opt/atlomy/database_backups/latest_backup.tar.gz -C /var/lib/postgresql/data
                chown -R postgres:postgres /var/lib/postgresql/data
                echo "‚úÖ Backup extracted successfully"
                
                # Restore the database
                echo "üîÑ Restoring database..."
                sudo -u postgres pg_restore -h "$POSTGRES_HOST" -U "$POSTGRES_USER" -d "$POSTGRES_DB" /var/lib/postgresql/data/latest_backup.dump
                echo "‚úÖ Database restored successfully"
                echo "postgres_data_status=populated" >> $GITHUB_OUTPUT
              else
                echo "‚ö†Ô∏è No backup file found. Skipping restoration."
                exit 1
              fi
            fi
          EOF

  notify-status:
    if: always()
    needs: [database-restoration]
    runs-on: ubuntu-latest
    steps:
      - name: Determine Workflow Status
        run: |
          if [[ "${{ needs.database-restoration.result }}" == 'success' ]]; then
            echo "‚úÖ Database Restoration Completed Successfully"
          else
            echo "‚ùå Database Restoration Failed"
            exit 1
          fi
